{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img style=\"float: center;\" src=\"images/CI_horizontal.png\" width=\"600\"></center>\n",
    "<center>\n",
    "    <span style=\"font-size: 1.5em;\">\n",
    "        <a href='https://www.coleridgeinitiative.org'>Website</a>\n",
    "    </span>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> Julia Lane, Benjamin Feder, Angela Tombari, Ekaterina Levitskaya, Tian Lou, Lina Osorio-Copete. </center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outcome measurement and imputation\n",
    "\n",
    "## Introduction\n",
    "\n",
    "What should you do when you encounter missing values in your data? Unfortunately, there is usually no *right* answer. However, you can try to impute these missing values, providing your best guess for each missing point's true value. Here, you will learn how to implement common imputation methods you can use in approaching missing values in your own work.\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "* Explore options for imputing missing values\n",
    "\n",
    "* Visualize estimate changes following imputation\n",
    "\n",
    "In this notebook, you will focus on 2012-13 Kentucky graduates' earnings during their first year after graduation, particularly in their first and fourth quarters after graduation. Recall that in the [Data Exploration](03_Dataset_Exploration.ipynb) notebook, you initially examined the earnings distribution for all members of this cohort who had positive earnings in this time period in Kentucky. To evaluate the earnings outcomes of all 2012-13 Kentucky graduates, you need to decide what to do when you cannot find their earnings in the Kentucky Unemployment Insurance (UI) wage records. A person may not appear in Kentucky's UI wage records for several reasons:\n",
    "- The person is unemployed. \n",
    "- The person is out of labor force, e.g., schooling, childcare, etc...\n",
    "- The person was employed outside of Kentucky.\n",
    "- The person's job is not covered in UI wage records, e.g.,self-employed, independent contractors, federal government works, etc. <a href='https://www.nap.edu/read/10206/chapter/11#294'>(Hotz and Scholz, 2002)</a>\n",
    "\n",
    "You will explore the resulting earnings outcomes after applying different earnings imputation methods. The methods covered in this notebook include:\n",
    "- Dropping all \"missing\" values\n",
    "- Filling in zero for people who do not have records in Kentucky UI wage records data \n",
    "- Substituting missing values with the average earnings of people who are in the same degree fields and have the same gender\n",
    "- Regression imputation\n",
    "- Adding in Ohio, Indiana, Missouri, Tennessee, and Illinois UI wage records for the cohort in question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R Setup and Database Connection\n",
    "\n",
    "Before you begin, you need to run the code cells below to import the libraries and connect to our PostgreSQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#database interaction imports\n",
    "library(DBI)\n",
    "library(RPostgreSQL)\n",
    "\n",
    "# for data manipulation/visualization\n",
    "library(tidyverse)\n",
    "\n",
    "# scaling data, calculating percentages, overriding default graphing\n",
    "library(scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an RPostgreSQL driver\n",
    "drv <- dbDriver(\"PostgreSQL\")\n",
    "\n",
    "# connect to the database\n",
    "con <- dbConnect(drv,dbname = \"postgresql://stuffed.adrf.info/appliedda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief Manipulation: Isolating Earnings during first quarter after graduation\n",
    "\n",
    "Before we start performing imputation, we need to do some quick data manipulation to isolate earnings from the first quarter after each individual's graduation. To do so, using the same approach as we did in the last [section](03_Data_Exploration.ipynb/#Common-Employment-Patterns) of the Data Exploration notebook, we will create a new column, `qrt_after_grad`, by dividing `time_after_grad` by 90 and rounding to the nearest whole number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read wage table into R\n",
    "qry <- \"\n",
    "select *\n",
    "from ada_ky_20.cohort_wages\n",
    "\"\n",
    "df_wages <- dbGetQuery(con, qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add in quarter after graduation\n",
    "df_wages <- df_wages %>%\n",
    "    mutate(q_after_grad = round(time_after_grad/90)) #default rounding behavior rounds to an integer\n",
    "\n",
    "# see unique values of q_after_grad\n",
    "df_wages %>%\n",
    "    distinct(q_after_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can simply create a data frame with just first quarter post-graduation wages using `filter()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter quarter 1 after graduation\n",
    "q1_wages <- df_wages %>%\n",
    "    filter(q_after_grad == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we will want to estimate the total wages for each `coleridge_id` in this quarter, not necessarily their wages per employer, let's aggregate `q1_wages` to find the total earnings for each member of this cohort in the entire quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate on coleridge_id\n",
    "q1_wages <- q1_wages %>%\n",
    "    group_by(coleridge_id) %>%\n",
    "    summarize(tot_wages = sum(wages)) %>%\n",
    "    ungroup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow(q1_wages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_num <- q1_wages %>%\n",
    "    summarize(n=n_distinct(coleridge_id))\n",
    "\n",
    "cat('The total graduates with positive earnings during their first quarter after graduation:', q1_num$n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the percentage of our cohort represented in `q1_wages`, let's load in our original cohort into R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry <- \"\n",
    "select *\n",
    "from ada_ky_20.cohort\n",
    "\"\n",
    "df <- dbGetQuery(con, qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat('That is', percent(q1_num$n/nrow(df), .01), 'of the study cohort.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red\">Checkpoint 1: Identifying Earnings in the Fourth Quarter after Graduation</h3>\n",
    "\n",
    "Given the code above, create a data subset `q4_wages` that contains all earnings for the cohort in their fourth quarter after graduation. How many members of our cohort had positive earnings in this quarter? Do you expect this number to be higher or lower than the number in the first quarter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add graduates without positive earnings for Q1\n",
    "\n",
    "Our current data frame, `q1_wages`, only contains individuals with positive earnings in their first quarter after graduation in Kentucky. Let's add in members of our cohort who did not appear in Kentucky's wage records during this time period, as well the additional variables from the original cohort table to better describe the individuals. This will let us easily analyze different earnings distributions in the cohort's first quarter after graduation as we progress throughout this notebook.\n",
    "\n",
    "We can do so by using a `left_join()` of the original cohort, `df`, to `q1_wages`, as this will add in one row for each `coleridge_id` in the original cohort that was not included in `q1_wages`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add in employment outcomes for all of those in the original cohort\n",
    "q1_all_wages <- df %>%\n",
    "    left_join(q1_wages, c(\"coleridge_id\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a quick check, we can see if the number of individuals in `q1_all_wages` that either have or do not have null wages makes sense given the total number of individuals in the cohort that were in `q1_wages`. We can do so by adding in an indicator variable if the `wages` column was null for each potential wage record in `q1_all_wages`, and then counting the number of distinct individuals based on this new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# employment outcomes for all of those in our original cohort\n",
    "q1_all_wages %>%\n",
    "    mutate(wage_ind = ifelse(is.na(tot_wages), 'no', 'yes')) %>%\n",
    "    group_by(wage_ind) %>%\n",
    "    summarize(n=n_distinct(coleridge_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of individuals in q1_wages\n",
    "q1_num$n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that these numbers make sense. If they did not add up, chances are there was an issue with the details of your join.\n",
    "\n",
    "For future usage, let's add the gender, birth year, and corresponding `ssn` to each individual in `q1_all_wages`. All three of these variables can be accessed within the table `master_person` in the `kystats_2020` schema. Let's load the contents of this table into R in preparation for the join, but only the contents for those in the original cohort.\n",
    "\n",
    ">Note: `ssn` is a hashed value to prevent direct reidentification of any individual within the ADRF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load master_person into R\n",
    "qry <- \"\n",
    "select *\n",
    "from kystats_2020.master_person\n",
    "where coleridge_id in (select coleridge_id from ada_ky_20.cohort)\n",
    "\"\n",
    "master_person <- dbGetQuery(con, qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see every individual is in master_person\n",
    "nrow(master_person)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now simply `left_join()` `master_person` to `q1_all_wages` to find the corresponding gender, birth year, and ssn values for each individual in `q1_all_wages`. To ensure we are just selecting these specific columns from `master_person`, we can de-select all of the other columns in `master_person`, all of which start with `ceds`.\n",
    "\n",
    "> The `rowid` and `contentarea` columns will also not provide any additional information to the resulting data frame, so we will de-select these variables as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join and de-select unnecessary variables and see the names of the columns\n",
    "q1_all_wages %>%\n",
    "    left_join(master_person, 'coleridge_id') %>%\n",
    "    select(-c(starts_with('ceds'), starts_with('rowid'), starts_with('contentarea'))) %>%\n",
    "    names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update q1_all_wages\n",
    "q1_all_wages <- q1_all_wages %>%\n",
    "    left_join(master_person, 'coleridge_id') %>%\n",
    "    select(-c(starts_with('ceds'), starts_with('rowid'), starts_with('contentarea')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to confirm, we can check to see if the number of rows in `q1_all_wages` is equal to the number of rows in `df`, the original cohort, as each individual in the original cohort should correspond to a single row regardless of employment status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow(df) == nrow(q1_all_wages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also check to see if we have any missing values for our demographic variables. If so, let's fill these in as `unknown` so they won't be dropped in future analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see number of na values by column\n",
    "colSums(is.na(q1_all_wages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will not be using `kpeds_major2` in this notebook, we will simply just use `replace_na()` for `gender` and `birthyear`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace na\n",
    "q1_all_wages<-q1_all_wages %>%\n",
    "    replace_na(list(\n",
    "        gender = 'U',\n",
    "        birthyear='unknown'\n",
    "    )\n",
    "              )\n",
    "\n",
    "# see na distribution now\n",
    "colSums(is.na(q1_all_wages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Theoretically, you could apply these imputation methods to these missing demographic values. However, for the purposes of this notebook, we will focus our imputation techniques on missing earnings values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red\">Checkpoint 2: Replicate for Q4</h3>\n",
    "\n",
    "Create a data frame `q4_all_wages` that mirrors `q1_all_wages` except for Q4. Feel free to add in as many code cells as you deem necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute Wage Values\n",
    "\n",
    "Now that we have confirmed that our `q1_all_wages` dataframe is ready to use for testing our imputation methods, we can get started. To recall, here are the five methods we will be trying out in this notebook:\n",
    "1. Dropping all people with \"missing\" values on the variable of interest (Q1 wages)\n",
    "2. Filling in zero for people who do not have records in Kentucky UI data\n",
    "3. Filling in missing values with the average Kentucky UI earnings of people who are in the same degree fields and have the same gender\n",
    "4. Regression\n",
    "5. Filling in missing values by adding in Ohio, Indiana, Missouri, Tennessee, and Illinois UI records for the cohort in question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Drop All Missing Values\n",
    "\n",
    "First, let's look at the earnings outcomes during first quarter after graduation when we drop all missing earnings values. Here, by ignoring potentially non-missing values, we are hoping that they mirror the same distribution as the present one. Although this is fairly common, you should **never, ever, ever** use this method in practice. \n",
    "\n",
    "> Deleting missing values is often called listwise deletion and essentially assumes that missing values are missing completely at random (MCAR). For a scholarly treatment of this issue, see (amongst others): \n",
    "> - Rubens (1976) \"Inference and Missing Data\" for the initial presentation, or\n",
    "> - Peugh and Enders (2004) \"Missing Data in Educational Research: A Review of Reporting Practices and Suggestions for Improvement\" for a more recent discussion.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop missing values\n",
    "q1_no_missing <- q1_all_wages %>%\n",
    "    filter(!is.na(tot_wages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see earnings distribution\n",
    "summary(q1_no_missing$tot_wages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:red\">Checkpoint 3: Replicate for Q4</h4>\n",
    "\n",
    "What does the earnings distribution look like for Q4 when you drop missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fill in Missing Values with Zero\n",
    "\n",
    "Next, let's see how the earnings distribution shifts when we encode all missing earnings outcomes as 0. Here, we are assuming that all missing earnings are due to unemployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill all null tot_wages with 0\n",
    "q1_wages_zero <- q1_all_wages %>%\n",
    "    mutate(tot_wages = ifelse(is.na(tot_wages), 0, tot_wages)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the distribution. How does it vary from the distribution you get in method 1?\n",
    "summary(q1_wages_zero$tot_wages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat('Average earnings if missing wages are dropped is $', round(mean(q1_no_missing$tot_wages), 2), sep = '', '.')\n",
    "\n",
    "cat('\\nAverage earnings if missing wages are imputed as 0 is $', round(mean(q1_wages_zero$tot_wages), 2), sep = '', '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:red\">Checkpoint 4: Replicate for Q4</h4>\n",
    "\n",
    "What does the earnings distribution look like for Q4 when you fill missing values with zero?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fill in Missing Values with Major/Gender Mean Earnings\n",
    "\n",
    "Now, instead of either ignoring missing values or assuming the earnings are 0, we will try imputing missing earnings for each individual as the average quarterly earnings of the other individuals in our cohort of the same `gender` and `kpeds_major1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, our strategy is as follows:\n",
    "- Using populated wages, find mean earnings for each major by gender\n",
    "- Merge the mean earnings, based on major and gender, to the overall cohort\n",
    " - creates an additional column `mean_wages`\n",
    "- Recode so that missing values are populated with mean earnings\n",
    " - data stored in a new column `imputed_wages`\n",
    "\n",
    "\n",
    ">Note: This process is frequently termed mean imputation. Implementing this method will compress the variance and covariance of the imputed variable, resulting in biased parameter estimates for all parameters except the mean (Peugh & Enders, 2004, p.529). In this example, we are assuming that the missing values in wages are conditional on both gender and major. We also assume that the missingness is not truly indicative of lack of wages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean earnings by gender/kpeds_major1 grouping\n",
    "q1_all_wages %>%\n",
    "    group_by(gender, kpeds_major1) %>%\n",
    "    summarize(mean_wages = mean(tot_wages, na.rm=T)) %>%\n",
    "    head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean earnings by gender/kpeds_major1 grouping saved\n",
    "q1_major_gend <- q1_all_wages %>%\n",
    "    group_by(gender, kpeds_major1) %>%\n",
    "    summarize(mean_wages = mean(tot_wages, na.rm=T)) %>%\n",
    "    ungroup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will merge the two DataFrames, `q1_major_gend` and `q1_all_wages` using `inner_join`.\n",
    "> Note: `left_join()` would also work in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if join works\n",
    "q1_all_wages %>%\n",
    "    inner_join(q1_major_gend, by=c('gender', 'kpeds_major1')) %>%\n",
    "    head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save join results to q1_joined_major_gend\n",
    "q1_joined_major_gend <- q1_all_wages %>%\n",
    "    inner_join(q1_major_gend, by=c('gender', 'kpeds_major1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can add a new column to `q1_joined_major_gend` to include the mean wage, based on gender and major, *if* the individual did not appear in the Kentucky UI wage records data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if mutation works as designed\n",
    "q1_joined_major_gend %>%\n",
    "    mutate(imputed_wages = ifelse(is.na(tot_wages), mean_wages, tot_wages)) %>%\n",
    "    select(tot_wages, mean_wages, imputed_wages) %>%\n",
    "    head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save mutation to q1_major_gend_impute\n",
    "q1_major_gend_impute <- q1_joined_major_gend %>%\n",
    "    mutate(imputed_wages = ifelse(is.na(tot_wages), mean_wages, tot_wages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In using this method, there is a chance we cannot impute missing values for all individuals in the cohort. If `imputed_wages` is still `NA`, we can assume there were no individuals in the cohort with non-missing earnings with the same major/gender combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if any still don't have imputed earnings\n",
    "q1_major_gend_impute %>%\n",
    "    filter(is.na(imputed_wages)) %>%\n",
    "    summarize(n=n())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, it seems as though we do not have available earnings for every combination of gender and primary degree. For the sake of the exercise, we will ignore the earnings of those whose we could not impute using this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(q1_major_gend_impute$imputed_wages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:red\">Checkpoint 5: Replicate for Q4</h4>\n",
    "\n",
    "Impute missing earnings values as the mean earnings of individuals in the cohort with the same gender (`gender`) and degree designation (`kpeds_major1`) in quarter 4. What does the earnings distribution look like? For how many individuals could you not impute values using this method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Regression imputation\n",
    "\n",
    "We can also use regression to try to get more accurate earnings values. We will build a regression equation from the obervations for which we know the earnings, then use the equation to predict the missing earnings values. This is, in effect, an extension of the mean imputation by subgroup. Here, we will use demographic information of graduates such as birth year, gender, institution of graduation, date of degree received, and if the individual received a STEM degree.\n",
    "\n",
    "> Note: We will not be checking the assumptions associated with linear regressions, as this example is aimed at merely displaying how to use a linear regression for imputation. If you plan on using regression imputation, please check all assumptions before employing a predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to variables included in regression analysis\n",
    "q1_reg <- q1_all_wages %>%\n",
    "    select(coleridge_id, tot_wages, birthyear, gender, kpeds_instname, kpeds_isstem, deg_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see types of the variables\n",
    "glimpse(q1_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, it may make sense for `birthyear` to be a numeric variable rather than a character vector, as there may be some predictive power in numerically analyzing the ages of the graduates. Let's change `birthyear` to a `numeric` variable.\n",
    "\n",
    "> Null birth years were previously replaced with a character vector. Any individual with an unknown birth year will be dropped to allow conversion to a numeric variable for imputation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see types of the variables after type change\n",
    "q1_reg %>%\n",
    "    mutate(birthyear = as.numeric(birthyear)) %>%\n",
    "    glimpse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save change of types of variables\n",
    "q1_reg_sub <- q1_reg %>%\n",
    "    mutate(birthyear = as.numeric(birthyear))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will build the model using the members of our cohort with non-missing wages, we will split `q1_reg_sub` into two datasets, one for testing (`q1_wages_na`) and one for training (`q1_wages_pred`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing sets\n",
    "# don't need tot_wages because they are null \n",
    "q1_wages_na <- q1_reg_sub %>%\n",
    "    filter(is.na(tot_wages)) %>%\n",
    "    select(-c(tot_wages))\n",
    "\n",
    "q1_wages_pred <- q1_reg_sub %>%\n",
    "    filter(!is.na(tot_wages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model creation process for a linear regression can be done using the `lm()` function. The variable we are trying to predict is on the left-hand side of `lm()` before the `~`, and the predictors are all of the variables on the right-hand side of the `~`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model and fit coefficients\n",
    "q1_wages_model <- lm(tot_wages ~ birthyear + gender + kpeds_instname + kpeds_isstem + deg_date, data = q1_wages_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have fit coefficients for each of the predictors in the model, we can predict the `tot_wages` variable for the test set using `predict()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict earnings for test set\n",
    "pred_earnings <- data.frame(tot_wages = predict(q1_wages_model, newdata=q1_wages_na))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see predicted earnings\n",
    "head(pred_earnings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the output for `predict()` retains the same order of rows from `q1_wages_na`, we can add the `tot_wages` variable from `pred_earnings` into the existing `q1_wages_na` data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see updated data frame with predicted earnings\n",
    "cbind(q1_wages_na, pred_earnings) %>% \n",
    "    head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated data frame\n",
    "q1_wages_na_w_earnings <- cbind(q1_wages_na, pred_earnings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, before we can see the effects of the imputation method, we need to combine our training set, which already has `tot_wages`, with our testing set and its predicted `tot_wages`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine training and testing sets\n",
    "rbind(q1_wages_na_w_earnings, q1_wages_pred) %>% \n",
    "    head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save combined training and testing sets\n",
    "q1_reg_earnings <- rbind(q1_wages_na_w_earnings, q1_wages_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see the entire earnings distribution for the cohort after applying regression imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see earnings distribution for full cohort\n",
    "summary(q1_reg_earnings$tot_wages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see earnings distribution for imputed portion of cohort\n",
    "summary(q1_wages_na_w_earnings$tot_wages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><h4> Checkpoint 6: Switch `kpeds_isstem` with `deg_class` and re-run the regression</h4></font> \n",
    "\n",
    "When you switch `kpeds_isstem` with `deg_class` in the regression, how does the earnings distribution compare to the one using the previous linear regression to impute values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Add in Ohio, Indiana, Missouri, Tennessee, and Illinois UI data\n",
    "\n",
    "Finally, let's see how the earnings distribution changes when we add in some bordering states' UI wage records. You will see how we joined Ohio, Indiana, Missouri, Tennessee and Illinois UI wage records to our `cohort` table. Afterwards, we will combine these tables to analyze the overall earnings distribution.\n",
    "\n",
    "By adding in contiguous states' wage records, we should be able to capture most earnings of our cohort that were outside of Kentucky.\n",
    "\n",
    "Recall that in the Data Exploration [notebook](03_Data_Exploration.ipynb/#Join-Cohort-to-Ohio's-UI-Wage-Records), we created the permanent table `oh_wages` by joining `cohort_w_ssns` to `small_ohio_ui`, which was a subset of the entire UI wage records within Ohio. The following SQL queries created `in_wages`, `tn_wages`, `il_wages`, and `mo_wages`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\tcreate table ada_ky_20.in_wages as \n",
    "    select b.uiacct::varchar as employeeno, b.wages, b.job_date, a.coleridge_id, a.degreegroup, a.degreerank, \n",
    "    a.kpeds_major1, a.kpeds_major1_cip, a.kpeds_instname, a.kpeds_sector, a.deg_date, (b.job_date - a.deg_date) as time_after_grad, \n",
    "    'IN'::varchar as state, a.deg_class\n",
    "    from ada_ky_20.cohort_w_ssns a\n",
    "    left join ada_ky_20.small_indiana_ui b\n",
    "    on a.ssn = b.ssn\n",
    "    where b.job_date > a.deg_date AND (a.deg_date + '1 year'::interval) >= b.job_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    create table ada_ky_20.mo_wages as \n",
    "    select b.empr_no::varchar as employeeno, b.wage as wages, b.job_date, a.coleridge_id, a.degreegroup, a.degreerank, \n",
    "    a.kpeds_major1, a.kpeds_major1_cip, a.kpeds_instname, a.kpeds_sector, a.deg_date, (b.job_date - a.deg_date) as time_after_grad, \n",
    "    'MO'::varchar as state, a.deg_class\n",
    "    from ada_ky_20.cohort_w_ssns a\n",
    "    left join ada_ky_20.small_mo_ui b\n",
    "    on a.ssn = b.ssn\n",
    "    where b.job_date > a.deg_date AND (a.deg_date + '1 year'::interval) >= b.job_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    create table ada_ky_20.tn_wages as \n",
    "    select b.empr_nbr::varchar as employeeno, b.wge_amt as wages, b.job_date, a.coleridge_id, a.degreegroup, a.degreerank, \n",
    "    a.kpeds_major1, a.kpeds_major1_cip, a.kpeds_instname, a.kpeds_sector, a.deg_date, (b.job_date - a.deg_date) as time_after_grad, \n",
    "    'TN'::varchar as state, a.deg_class\n",
    "    from ada_ky_20.cohort_w_ssns a\n",
    "    left join ada_ky_20.small_tn_ui b\n",
    "    on a.ssn = b.ssn\n",
    "    where b.job_date > a.deg_date AND (a.deg_date + '1 year'::interval) >= b.job_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    create table ada_ky_20.il_wages as \n",
    "    select b.empr_no::varchar as employeeno, b.wage as wages, b.job_date, a.coleridge_id, a.degreegroup, a.degreerank, \n",
    "    a.kpeds_major1, a.kpeds_major1_cip, a.kpeds_instname, a.kpeds_sector, a.deg_date, (b.job_date - a.deg_date) as time_after_grad, \n",
    "    'IL'::varchar as state, a.deg_class\n",
    "    from ada_ky_20.cohort_w_ssns a\n",
    "    left join ada_ky_20.small_illinois_ui b\n",
    "    on a.ssn = b.ssn\n",
    "    where b.job_date > a.deg_date AND (a.deg_date + '1 year'::interval) >= b.job_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's briefly explore these tables to see how many `coleridge_id` values these created tables captured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in IN table \n",
    "qry = \"\n",
    "select count(distinct(coleridge_id))\n",
    "from ada_ky_20.in_wages\n",
    "\"\n",
    "dbGetQuery(con, qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in MO table \n",
    "qry = \"\n",
    "select count(distinct(coleridge_id))\n",
    "from ada_ky_20.mo_wages\n",
    "\"\n",
    "dbGetQuery(con, qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in IL table \n",
    "qry = \"\n",
    "select count(distinct(coleridge_id))\n",
    "from ada_ky_20.il_wages\n",
    "\"\n",
    "dbGetQuery(con, qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in TN table \n",
    "qry = \"\n",
    "select count(distinct(coleridge_id))\n",
    "from ada_ky_20.tn_wages\n",
    "\"\n",
    "dbGetQuery(con, qry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have access to six tables that have 2013 AY Kentucky graduates' UI records from the six states. We can append these tables by using `union` in SQL.\n",
    "\n",
    ">Note: In this case `union` and `union all` are equivalent. The `union` command will remove duplicate rows and should be avoided if duplication of rows is meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try combining cohort_wages and oh_wages\n",
    "qry = \"\n",
    "select coleridge_id, degreegroup, degreerank, kpeds_major1, kpeds_major1_cip, kpeds_instname, kpeds_sector, deg_date, \n",
    "wages, job_date, time_after_grad, deg_class, 'KY'::varchar as state\n",
    "from ada_ky_20.cohort_wages\n",
    "UNION ALL\n",
    "select coleridge_id, degreegroup, degreerank, kpeds_major1, kpeds_major1_cip, kpeds_instname, kpeds_sector, deg_date, \n",
    "wages, job_date, time_after_grad, deg_class, state\n",
    "from ada_ky_20.oh_wages\n",
    "UNION ALL\n",
    "select coleridge_id, degreegroup, degreerank, kpeds_major1, kpeds_major1_cip, kpeds_instname, kpeds_sector, deg_date, \n",
    "wages, job_date, time_after_grad, deg_class, state\n",
    "from ada_ky_20.in_wages\n",
    "UNION ALL\n",
    "select coleridge_id, degreegroup, degreerank, kpeds_major1, kpeds_major1_cip, kpeds_instname, kpeds_sector, deg_date, \n",
    "wages, job_date, time_after_grad, deg_class, state\n",
    "from ada_ky_20.il_wages\n",
    "UNION ALL\n",
    "select coleridge_id, degreegroup, degreerank, kpeds_major1, kpeds_major1_cip, kpeds_instname, kpeds_sector, deg_date, \n",
    "wages, job_date, time_after_grad, deg_class, state\n",
    "from ada_ky_20.tn_wages\n",
    "UNION ALL\n",
    "select coleridge_id, degreegroup, degreerank, kpeds_major1, kpeds_major1_cip, kpeds_instname, kpeds_sector, deg_date, \n",
    "wages, job_date, time_after_grad, deg_class, state\n",
    "from ada_ky_20.mo_wages\n",
    "\"\n",
    "\n",
    "#this is the critical difference- here we assign the results to a data frame in our environment\n",
    "combined_wages <- dbGetQuery(con, qry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `combined_wages` data frame contains earnings observations for the cohort in all four quarters post-graduation. For consistency, let's focus on just the earnings for their first quarter after graduation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for first quarter\n",
    "q1_combined_wages <- combined_wages %>%\n",
    "    mutate(q_after_grad = round(time_after_grad/90)) %>% \n",
    "    filter(q_after_grad == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many distinct `coleridge_id` are in `q1_combined_wages`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see number of distinct coleridge_id values \n",
    "n_distinct(q1_combined_wages$coleridge_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may recall, the number of unique `coleridge_id` values in `q1_combined_wages` is not the same number as in the original cohort. Since we just combined all earnings observations for these six states, we are still missing a portion of the original cohort that did not appear in any of these states' UI wage records in their first quarter after graduation.\n",
    "\n",
    "To allow for reasonable comparison, let's add in these individuals using another `left_join()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add in those present in df but not q1_combined_wages\n",
    "q1_all_combined_wages <- df %>%\n",
    "    left_join(q1_combined_wages, c('coleridge_id', 'degreegroup', 'degreerank', 'kpeds_major1', 'kpeds_major1_cip', \n",
    "                                'kpeds_instname', 'kpeds_sector', 'deg_date', 'deg_class'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see number of unique coleridge_ids\n",
    "n_distinct(q1_all_combined_wages$coleridge_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we have the UI wage records for the cohort in six states, let's quickly explore `q1_all_combined_wages`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check how many people have earnings in each state\n",
    "q1_all_combined_wages %>%\n",
    "    group_by(state) %>%\n",
    "    summarize(n=n_distinct(coleridge_id)) %>%\n",
    "    arrange(desc(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the breakdown of the amount of states each person worked in during this time frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of jobs in different states by coleridge_id\n",
    "q1_all_combined_wages %>%\n",
    "    filter(!is.na(state)) %>%\n",
    "    group_by(coleridge_id) %>%\n",
    "    summarize(n_states = n_distinct(state)) %>%\n",
    "    ungroup() %>%\n",
    "    group_by(n_states) %>%\n",
    "    summarize(n=n_distinct(coleridge_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how many missing values we have filled in by adding additional states' UI records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat('By adding in UI wage records from a handful of bordering states, we have managed to find wage records for', \n",
    "   n_distinct(q1_combined_wages$coleridge_id) - n_distinct(q1_wages$coleridge_id),\n",
    "   'more people, as well as augmented earnings for some others.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the earnings distribution after we add UI records from other states\n",
    "q1_combined_agg_wages <- q1_all_combined_wages %>%\n",
    "    group_by(coleridge_id) %>%\n",
    "    summarize(tot_wages = sum(wages))\n",
    "\n",
    "summary(q1_combined_agg_wages$tot_wages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Earnings Distributions\n",
    "\n",
    "We can quickly determine if these different imputation methods significantly altered the pre-imputation wage distribution by visualizing the overall earnings distribution. Plotting side-by-side boxplots can be an effective choice. To do so, we need to bind the earnings from all of these methods by rows, meaning they must have the same columns. For the sake of simplicity, we will have three columns in this data frame:\n",
    "\n",
    "- `coleridge_id`, the person identifier\n",
    "- `tot_wages`, cumulative earnings in first quarter post-graduation\n",
    "- `method`, type of imputation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapt q1_no_missing\n",
    "q1_no_missing %>%\n",
    "    select(coleridge_id, tot_wages) %>% head()\n",
    "\n",
    "q1_no_missing <- q1_no_missing %>%\n",
    "    select(coleridge_id, tot_wages) %>%\n",
    "    mutate(method = 'remove missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapt q1_reg_earnings\n",
    "q1_reg_earnings%>%\n",
    "    select(coleridge_id, tot_wages) %>% head()\n",
    "\n",
    "q1_reg_earnings <- q1_reg_earnings %>%\n",
    "    select(coleridge_id, tot_wages) %>%\n",
    "    mutate(method = 'regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapt q1_wages_zero\n",
    "q1_wages_zero %>%\n",
    "    select(coleridge_id, tot_wages) %>% head()\n",
    "\n",
    "q1_wages_zero <- q1_wages_zero %>%\n",
    "    select(coleridge_id, tot_wages) %>%\n",
    "    mutate(method = 'zero')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adapt q1_major_gend_impute\n",
    "q1_major_gend_impute %>% select(coleridge_id, imputed_wages) %>% rename(tot_wages = imputed_wages) %>% head()\n",
    "\n",
    "q1_major_gend_impute <- q1_major_gend_impute %>%\n",
    "    select(coleridge_id, tot_wages) %>%\n",
    "    mutate(method = 'mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that these methods all have the same column names, we can feed them into `rbind()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine earnings from all methods\n",
    "all_methods <- rbind(q1_major_gend_impute, q1_reg_earnings, q1_no_missing, q1_wages_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of plotting the earnings distributions of each method one at a time, we can plot them all in a side-by-side fashion by using the `facet_grid()` function as we did in the Data Visualization [notebook](05_Data_Visualization.ipynb/#Distribution-of-quarterly-wages-by-degree-rank)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot of all methods\n",
    "all_methods %>%\n",
    "    ggplot(aes(x=tot_wages, y ='')) +\n",
    "    geom_boxplot() + \n",
    "    facet_grid(method ~ .) +\n",
    "    labs(\n",
    "        title = \"The Q1 Earnings Distribution's Quartiles up to the 75th are largely affected by \\n imputation method\",\n",
    "        x='Quarter 1 Earnings',\n",
    "        caption = 'Source: KPEDS and KY UI wage records data'\n",
    "    ) +\n",
    "    theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple histograms\n",
    "\n",
    "We can also look at the differences in the earnings distribution by looking at side-by-side histograms. Instead of using the `geom_` layer `geom_boxplot()`, we will use `geom_histogram()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_methods %>%\n",
    "    ggplot(aes(x=tot_wages)) +\n",
    "    geom_histogram() + \n",
    "    facet_grid(method ~ .) +\n",
    "    labs(\n",
    "        title = 'REDACTED has a significant change on the overall earnings distribution',\n",
    "        y = 'Density',\n",
    "        x='Quarterly Wages',\n",
    "        caption = 'Source: KPEDS and KY UI wage records data'\n",
    "    ) +\n",
    "    theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red\">Checkpoint 7: Visualizing cross state earnings</h3>\n",
    "Add the cross state earnings distribution to either the above multiple histograms or boxplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Advanced: Using machine learning to impute values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To impute values, we can also use machine learning algorithms such as `K-nearest Neighbors` and `Decision Trees`. The principle behind `K-nearest Neighbors` is quite simple: the missing values can be imputed by values of \"closest neighbors\" - as approximated by other, known, features. \n",
    "\n",
    "For example, if we had cases where the data on earnings of some graduates was completely missing, we could approximate their earnings by referring to other characteristics which could be shared by major group (their 'closest neighbors' in terms of characteristics).\n",
    "\n",
    "The algorithm calculates the distance between the input values (the missing values) and helps to identify the nearest possible value based on other features (such as known characteristics of the closest major group). Imputing missing data using machine learning has become a research hotbed, and there are plenty of papers covering the various algorithms if you are curious."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Peugh, J. L., & Enders, C. K. (2004). Missing Data in Educational Research: A Review of Reporting Practices and Suggestions for Improvement. _Review of Educational Research_, 74(4), 525-556. doi: 10.3102/00346543074004525\n",
    "\n",
    "Rubin, D. B. (1976). Inference and Missing Data. _Biometrika_, 63(3), 581-592. doi:10.2307/2335739"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "adrf_r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
