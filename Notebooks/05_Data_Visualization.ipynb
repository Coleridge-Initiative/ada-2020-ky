{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: center;\" src=\"images/CI_horizontal.png\" width=\"600\">\n",
    "<center>\n",
    "    <span style=\"font-size: 1.5em;\">\n",
    "        <a href='https://www.coleridgeinitiative.org'>Website</a>\n",
    "    </span>\n",
    "</center>\n",
    "\n",
    "\n",
    "<center> Julia Lane, Benjamin Feder, Angela Tombari, Ekaterina Levitskaya, Tian Lou, Lina Osorio-Copete. </center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization in R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook you will learn how to use different visualization methods in R to explore and analyze your data. We will also talk about proper annotation of graphs in order to clearly and accurately communicate your results.\n",
    "\n",
    "We will cover the following methods:\n",
    "- **Histogram** \n",
    "(visualizing distributions, continuous variables)\n",
    "- **Bar plot**\n",
    "(visualizing relationships between numerical and categorical variables)\n",
    "- **Small multiples**\n",
    "(using a series of mini-graphs to compare information by different groups)\n",
    "- **Heatmap** \n",
    "(adding highlights to your data with color-coding)\n",
    "- **Geographic heatmap**\n",
    "(showing regional differences in your data)\n",
    "\n",
    "For all visualizations we are going to use an R package called `ggplot2` (`ggplot2` is included in the `tidyverse` suite of packages). The syntax of `ggplot2` in most cases stays the same:\n",
    "\n",
    "- you always start with `ggplot()` <br>\n",
    "- then, supply a dataset and aesthetic mapping with x and/or y variables, like this: `ggplot(dataset, aes(x = ..., y = ...)` <br>\n",
    "- and then you can add layers using `+` <br>\n",
    "for example, <br>\n",
    "`ggplot(dataset, aes(x = ... , y = ...) + geom_histogram()` to create a histogram, or <br>\n",
    "`ggplot(dataset, aes(x = ... , y = ...) + geom_histogram() + labs(title = 'My plot title')` to create a histogram and add a title for the graph, and so on.\n",
    "\n",
    "In this notebook we will visualize the following examples for our cohort of Kentucky graduates in the 2013 academic year (defined in the Data Exploration notebook):\n",
    "\n",
    "- Education experience:\n",
    "    - **Number of graduates by institution** (boxplot)\n",
    "    - **Number of graduates by origin county** (geographic heatmap)\n",
    "    - **Percentages of graduates who received their primary degrees within the seven major groups by Applachian status** (bar plot)\n",
    "    \n",
    "\n",
    "- Employment outcomes:\n",
    "    - **Distribution of quarterly wages by degree rank** (small multiples, histogram)\n",
    "    - **Percentage of graduates in five key sectors of employment by Appalachian status** (bar plot)\n",
    "    - **Employment patterns by quarters** (heatmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing necessary R libraries and connecting to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#database interaction imports\n",
    "library(DBI)\n",
    "library(RPostgreSQL)\n",
    "\n",
    "# for data manipulation/visualization\n",
    "library(tidyverse)\n",
    "library(lubridate)\n",
    "library(sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an RPostgreSQL driver\n",
    "drv <- dbDriver(\"PostgreSQL\")\n",
    "\n",
    "# connect to the database\n",
    "con <- dbConnect(drv,dbname = \"postgresql://stuffed.adrf.info/appliedda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can properly connect to our `appliedda` database, let's read in the permanent table `cohort` from the `ada_ky_20` schema. As a reminder, `cohort` contains the cohort we used in the Data Exploration notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in cohort table as df\n",
    "qry <- \"\n",
    "select * \n",
    "from ada_ky_20.cohort\n",
    "\"\n",
    "df <- dbGetQuery(con, qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see df\n",
    "glimpse(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning About our Graduates\n",
    "\n",
    "In the Data Exploration notebook, we found numerical summaries to answer a variety of questions that ultimately helped us understand our cohort a bit better. As you will see, some of these numerical summaries can be better conveyed via visualizations. In this section, we will introduce three visualizations:\n",
    "\n",
    "- A boxplot of the number of graduates by institution (`geom_boxplot()`)\n",
    "- A heatmap of origin counties of our graduates (`geom_sf()`)\n",
    "- Degree breakdowns by Appalachian status (`geom_bar()`)\n",
    "\n",
    "We will start by reusing the code from before to generate these numerical summaries, and then pipe (`%>%`) at least some portion of the resulting dataframe into a `ggplot()` string of functions to create the resulting visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of graduates by institution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our analysis of the most popular institutions by graduation, it seems as though a handful of insitutions in Kentucky tend to account for a significant proportion of its entire postsecondary graduating class. Let's further analyze that hypothesis by plotting a boxplot of the amount of graduates in our cohort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reminder, the code cell below uses the exact code we used to get to this calculation in the Data Exploration notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts by institution\n",
    "df %>%\n",
    "    count(kpeds_instname) %>%\n",
    "    arrange(desc(n)) %>%\n",
    "    head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a boxplot to inspect the overall distribution of the number of graduates for each institution. We can simply take the output from `count(kpeds_instname)` and use it as the first argument in our `ggplot()` call.\n",
    "\n",
    "> Note: We can ensure that we are only plotting one group by setting `x=\"\"` inside the `aes()` function. You will also see a manual line break to wrap the title: `\\n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full code for the plot\n",
    "df %>%\n",
    "    count(kpeds_instname) %>%\n",
    "    ggplot(aes(x=\"\", y=n)) + \n",
    "    geom_boxplot() +\n",
    "    labs(\n",
    "        title = 'The majority of institutions graduated around 1,000 students \\n in 2013',\n",
    "        y = 'Number of graduates',\n",
    "        x='',\n",
    "        caption = 'Source: KPEDS data'\n",
    "    ) +\n",
    "    theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This visualization shows us that there seem to be a handful of outlier institutions in terms of number of graduates in the 2013 academic year.  After establishing this baseline, we can see if there is any variation in the number of graduates by institution type. \n",
    "\n",
    "As you may recall from the Data Exploration notebook, we can either use `kpeds_sector` or `kpeds_sector_code`. Let's look at both of them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see counts by kpeds_sector and kpeds_sector_code\n",
    "df %>%\n",
    "    count(kpeds_sector, kpeds_sector_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have remembered that there are two potential `kpeds_sector` values that relate to the same sector code, with AIKCU and 4 year independent both corresponding to `kpeds_sector_code == 3`. Let's update `df` so that all AIKCU institutions are now referred to as 4 year independent ones. \n",
    "\n",
    "Once sector names are cleaned up, we will look at the distribution of each institution's number of graduates by institution type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update kpeds_sector\n",
    "df <- df %>%\n",
    "    mutate(kpeds_sector = ifelse(kpeds_sector == \"AIKCU\", \"4 year independent\", kpeds_sector))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use almost identical code from the first boxplot, except with `count(kpeds_instname, kpeds_sector)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts by institution\n",
    "# switch to just using labs and theme here\n",
    "df %>%\n",
    "    count(kpeds_instname, kpeds_sector) %>%\n",
    "    ggplot(aes(x=kpeds_sector, y=n)) + \n",
    "    geom_boxplot() +\n",
    "    labs(\n",
    "        title = 'The number of graduates differs by institution type',\n",
    "        y = 'Number of graduates',\n",
    "        x='Institution Type',\n",
    "        caption = 'Source: KPEDS data'\n",
    "    ) +\n",
    "    theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><h3> Checkpoint 1: New Aesthetics </h3></font> \n",
    "\n",
    "Recreate the same bar plot, except instead having a blank x-axis and the color differing by the institution type. Which of the two options do you prefer?\n",
    "\n",
    "> You can dictate the color as a separate argument inside `aes()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same boxplot except institution type differs based on color\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of graduates by origin county"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we wanted to show regional differences in the number of graduates by county using a map? A heatmap is a powerful visualization tool which allows for easy comparison and communication of regional differences to external audiences.\n",
    "\n",
    "We can leverage an available public table in our database with geographic coordinates of counties, as well as the `sf` package, which allows us to read in the geographic location information in one line of code (using `st_read` function) and prepare coordinate information for plotting. \n",
    "\n",
    "Before we do so, we will generate our base table of graduates by origin county.\n",
    "\n",
    ">We have already pulled our graduates (`df`) into our working environment. We still need enrollment information, which contains postsecondary student location of origin (`kpeds_enrollments.kpeds_statecountryoforigin` and `kpeds_enrollments.kpeds_countyoforigin`).  We will pull this information into our working environment as a data frame, `enroll`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read kpeds_enrollments into R\n",
    "qry <- \"\n",
    "select *\n",
    "from kystats_2020.kpeds_enrollments\n",
    "where kpeds_semesteryear in (2012, 2013)\n",
    "\"\n",
    "enroll <- dbGetQuery(con, qry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cell below, since we do not want any entries with `NA` values as the county and we want to make sure we can match each county to our table in the `public` schema, we will make sure all of the county names are in lowercase by using the `tolower()` function. Additionally, since an individual may have multiple enrollments within the time span of `enroll`, after we match all potential enrollments to each member of our cohort, we will keep only one enrollment entry, preferably (as indicated in the `arrange()` call) from the enrollment institution that matches the institution of graduation for each individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find counts by origin county in Kentucky\n",
    "# save output into a new data frame (cnty) in our working environment\n",
    "\n",
    "cnty <- df %>% \n",
    "    left_join(enroll, \"coleridge_id\") %>%\n",
    "    # added tolower because a few records have KENTUCKY instead of Kentucky\n",
    "    filter(tolower(kpeds_statecountryoforigin) == \"kentucky\", !is.na(kpeds_countyoforigin)) %>%\n",
    "    # some coleridge_ids became duplicated by join, so keep only 1, preferring 1 from graduating institution if available\n",
    "    arrange(coleridge_id, desc(kpeds_institution.x == kpeds_institution.y)) %>%\n",
    "    distinct(coleridge_id, .keep_all = TRUE) %>%\n",
    "    # now can count graduates by county of origin\n",
    "    count(kpeds_countyoforigin) %>%\n",
    "    mutate(kpeds_countyoforigin = tolower(kpeds_countyoforigin))\n",
    "\n",
    "# see cnty\n",
    "head(cnty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow(df)      # original coleridge_id count\n",
    "sum(cnty$n)  # record count after enrollment join:  decrease due to filter for in-state only and dropping graduates with no enrollment record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our table of graduate counts by origin county, We will use the `st_read` function in the `sf` package to read in the necessary geographic information for Kentucky: county codes, county names, polygons, and centroids of those polygons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get county codes, county names, polygons, and centroids of those polygons for Kentucky (fips code = '21')\n",
    "qry <- \n",
    "\"SELECT countyfp as county, LOWER(name) as name, geom, ST_X(ST_Centroid(geom)) as long, ST_Y(ST_Centroid(geom)) as lat\n",
    "FROM public.tl_2016_us_county\n",
    "WHERE statefp = '21'\n",
    "\"\n",
    "#read into R as df\n",
    "counties <- st_read(con,query=qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see counties\n",
    "head(counties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now join `counties` and `cnty`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join counties and cnty\n",
    "counties <- inner_join(counties, cnty, by=c(\"name\"=\"kpeds_countyoforigin\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see counties\n",
    "head(counties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create the map using `ggplot` and `geom_sf` as primary functions by feeding in `counties` as the initial argument.\n",
    "\n",
    ">Note: Text variables, like county name, can easily cause problems due to differences in format: all uppercase, all lowercase, or camelcase.  An easy solution is to convert everything to the same format as demonstrated above. It is also helpful to get a count of unique names in a dataframe before and after a join to check for errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot\n",
    "ggplot(counties) +                                              # insert the name of the main dataset here\n",
    "    geom_sf(aes(fill=n), color='white') +                       # in the fill parameter use \"count\" variable\n",
    "    scale_fill_gradient(low=\"light blue\",high=\"red\") +          # choose colors for the gradient\n",
    "    geom_text(aes(x=long, y=lat, label=name), size=2) +         # add county names as labels using centroids defined in the table\n",
    "    labs(\n",
    "        title = \"More graduates are originally from the [redacted] of Kentucky\",\n",
    "        caption = \"Source: KPEDS Data\"\n",
    "    ) +\n",
    "    theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note**: This heatmap shows one of the issues when displaying people by county in Kentucky. Out of 120 counties in the state, the population of just two (Jefferson County and Fayette County) comprise over 20% of the population of the state as a whole. Heatmaps on counts will tend to compress the scale for the remaining 118 counties. One solution is to use percentages based on some consistent metric, whether that be high school graduates, overall population within a certain age range, or enrollees from that area. Each of these would be presenting a different story and the denominator should be selected with care."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage of graduates in the 7 Major Groups by Appalachian status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may also be useful for us to visualize the differences in the percentage of graduates by major goups (used in the Postsecondary Feedback Report) based on the geographic location of the postsecondary institution. Bar plots can aid visual inspection of group differences as well as provide an effective communication tool for the outside audience (for example, if you would like to highlight a significant difference between groups as we do in the example below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall our seven major groupings column in df, `deg_class`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what were the names of those deg_class categories again?\n",
    "unique(df$deg_class) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need our handy institution crosswalk `kpeds_inst_xwalk`, which provides the Applachian status of each institution's primary campus location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read institution crosswalk into r\n",
    "qry <- \"\n",
    "select inst_code, wib, appalachian\n",
    "from kystats_2020.kpeds_inst_xwalk\n",
    "\"\n",
    "inst_xwalk <- dbGetQuery(con, qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can match on the institution code\n",
    "df_app <- df %>% \n",
    "    left_join(inst_xwalk, by=c(\"kpeds_institution\" = \"inst_code\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we can feed our data frame of the percentage of graduates in each degree field directly into our `ggplot()` call.\n",
    "\n",
    "> We can plot a side by side barplot by setting `position = position_dodge()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot percentages by degree group and appalachian status\n",
    "df_app %>%\n",
    "    count(deg_class, appalachian) %>%\n",
    "    group_by(appalachian) %>%\n",
    "    mutate(percent = (n/sum(n)) * 100) %>% #up to this point, we have been doing some classic dplyr work as introduced in the data exploration notebook\n",
    "    ggplot(aes(x=word(deg_class,1), y=percent, fill=as.factor(appalachian))) +\n",
    "    geom_bar(stat=\"identity\", position=position_dodge()) +\n",
    "    labs(\n",
    "        title = 'Graduates from Appalachian Institutions do not receive [redacted] degrees as often',\n",
    "        y = 'Percentage of graduates',\n",
    "        x='Degree Field',\n",
    "        fill = 'Appalachian Status',\n",
    "        caption = 'Source: KPEDS data'\n",
    "    ) +\n",
    "    theme_minimal() +\n",
    "    ylim(0,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><h3> Checkpoint 2: World Wide WIB </h3></font> \n",
    "\n",
    "Recreate this bar plot broken down by WIB.\n",
    ">Note: we have not introduced faceting, but feel free to look it up if you want each wib to display as a separate plot: `+ facet_wrap(~wib)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Employment outcomes\n",
    "\n",
    "Similar to how we visualized descriptive statistics to better understand the graduates within our cohort, we can use similar techniques to visualize descriptive statistics regarding our cohort's earnings and employment outcomes. In this section, we will walk through three visualizations:\n",
    "- Quarterly wages distribution via density plots by degree rank (`geom_density()` and `facet_grid()`)\n",
    "- A bar plot of Industry breakdowns by Appalchian status (`geom_bar()`)\n",
    "- A heatmap of employment patterns by cohort (`geom_tile()`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to read our employment outcomes for our cohort, which are stored in `cohort_wages`, into R.\n",
    ">Note: By now, you have probably noticed the utility of `glimpse()`.  Other functions you may find useful include: `head()`, `summary()`, `names()`, and `unique(df$variable)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read into R\n",
    "qry = \"\n",
    "select *\n",
    "from ada_ky_20.cohort_wages\n",
    "\"\n",
    "df_wages <- dbGetQuery(con, qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see df_wages\n",
    "glimpse(df_wages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of quarterly wages by degree rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a density plot (a smoothed version of a histogram) to visualize distributions of wages by degree rank in our cohort. \n",
    "\n",
    "When we want to compare multiple groups in one plot, there is a high chance that the plot will become overcrowded. A good solution for such case is using small multiples (a series of mini-graphs for each group which use the same scale and axes). In this example we will visualize the quarterly wage distribution for graduates by degree rank using mini-density plots for each degree rank.\n",
    "\n",
    "As before, we can find a rough distribution of all quarterly wages using our code from the Data Exploration notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of quarterly wages\n",
    "df_wages %>%\n",
    "    group_by(coleridge_id, job_date) %>%         #recall that job date was a created variable that combines year and quarter into a single date field\n",
    "    summarize(quarterly_wages = sum(wages)) %>%  #sums wages across all jobs held by a single person during this quarter\n",
    "    ungroup() %>%\n",
    "    select(quarterly_wages) %>%\n",
    "    summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In plotting, we will add in a grouping variable, `degreerank`, in our `group_by()` function. This will allow us to create separate grids based on the `degreerank` level.\n",
    "\n",
    "> Feel free to change the limit on the x-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "df_wages %>%\n",
    "    group_by(coleridge_id, job_date, degreerank) %>%\n",
    "    summarize(quarterly_wages = sum(wages)) %>%\n",
    "    ungroup() %>%\n",
    "    ggplot(aes(x=quarterly_wages)) +\n",
    "    geom_density() + \n",
    "    facet_grid(degreerank ~ .) +\n",
    "    labs(\n",
    "        title = 'Quarterly wages tend to [redacted] as the degree level [redacted]',\n",
    "        y = 'Density',\n",
    "        x='Quarterly Wages',\n",
    "        caption = 'Source: KPEDS and KY UI wage records data'\n",
    "    ) +\n",
    "    theme_minimal() +\n",
    "    xlim(0, 25000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><h3> Checkpoint 3: Working with `facet_grid()` </h3></font> \n",
    "\n",
    "Create a small multiples visualization with your own variables of interest.\n",
    ">Note: `facet_grid` and `facet_wrap` can frequently accomplish the same thing.  `facet_grid` is generally superior when trying to show some outcome split by two characteristics.  One example might be splitting wages by gender (found in `master_person`) and degree STEM classification (variable `kpeds_isstem` in the `kpeds_degree` table). Although these variables are not part of the current dataset, they could easily be added using the skills introduced in the data exploration notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Sectors by Institution Location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also inspect where graduates from institutions from different locations ended up by comparing the percentages of graduates employed in the five key sectors by Appalachian status. First, let's go ahead and create a new column `key_sect` to represent these sectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add in five key sectors\n",
    "# changed names a bit for viz\n",
    "df_wages <- df_wages %>%\n",
    "    mutate(key_sect = case_when(\n",
    "        majorindustry == \"Manufacturing\" ~ \"Manufacturing\",\n",
    "        majorindustry == \"Construction\" ~ \"Construction\",\n",
    "        majorindustry == \"Health Care and Social Assistance\" ~ \"Health Sciences\",\n",
    "        majorindustry == \"Transportation and Warehousing\" ~ \"Transportation\",\n",
    "         majorindustry %in% c(\"Professional, Scientific, and Technical Services\",\n",
    "                             \"Finance and Insurance\", \n",
    "                             \"Information\",\n",
    "                             \"Wholesale Trade\") ~ \"Business\",\n",
    "        TRUE ~ \"Non_Key\"\n",
    "    )\n",
    "          )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can match our graduates in `df_wages` by their institution to find their Appalachian status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can match on the institution code\n",
    "df_wages_app <- df_wages %>% \n",
    "    left_join(inst_xwalk, by=c(\"kpeds_institution\" = \"inst_code\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can graph the percentage of graduates in each of the sectors grouped by the Appalachian status of their institution, since an individual may have multiple rows of employment based on their employment history in their first year post-graduation, we must find the number of unique individuals, i.e. the number of individuals who received any wages in Kentucky, broken down by the location of the institution of their most recent graduation. We will assign this output to `app_break`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find breakdown of employed graduates in KY by appalachian status of institution\n",
    "app_break<-df_wages_app %>% \n",
    "    group_by(appalachian) %>%\n",
    "    summarize(n_total=n_distinct(coleridge_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did in the Data Exploration notebook, we can proceed by finding the percentage of graduates in each of the sectors grouped by the Appalachian status of their institution, and then use those counts as an input to `ggplot()`. To find the percentage of individuals employed in the sector in at least one quarter, we will divide these counts by those in `app_break`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar plot of percentages by industry and appalachian status\n",
    "df_wages_app %>%\n",
    "    group_by(key_sect, appalachian) %>%\n",
    "    summarize(n = n_distinct(coleridge_id)) %>%\n",
    "    ungroup() %>%\n",
    "    left_join(app_break, \"appalachian\") %>%\n",
    "    mutate(pct = (n/n_total)*100) %>%    \n",
    "    ggplot(aes(x=word(key_sect, 1), y=pct, fill=as.factor(appalachian))) +\n",
    "    geom_bar(stat=\"identity\", position=position_dodge()) +\n",
    "    labs(\n",
    "        title = 'Graduates from Appalachian Institutions were more likely to end up in [redacted]',\n",
    "        y = 'Percentage of graduates',\n",
    "        x='Sector',\n",
    "        fill = 'Appalachian Status',\n",
    "        caption = 'Source: KPEDS and KY UI wage records data'\n",
    "    ) +\n",
    "    theme_minimal() +\n",
    "    ylim(0,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><h3> Checkpoint 4: WIB Breakdown </h3></font> \n",
    "\n",
    "Recreate the same bar plot by WIB status.\n",
    "\n",
    ">Hint: You may want to leverage `facet_grid` or `facet_wrap` to make the plot easier to read. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employment patterns by quarters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final visualization in this notebook is a heatmap table of employment patterns by quarter for our cohort of Kentucky graduates. We will start by reading in the .csv file of employment patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns <- read_csv(\"/nfshome/INSERT_USERNAME/patterns.csv\") %>% \n",
    "    select(-X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see patterns\n",
    "patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save counts to use later in the heatmap - we cannot use the counts as index, as there could be duplicate values \n",
    "counts <- patterns$count\n",
    "pcts <- patterns$pct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will add index with unique sequential numbers and remove the `count` AND `pct` columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns$Pattern <- seq.int(nrow(patterns))\n",
    "patterns$count <- NULL\n",
    "patterns$pct <- NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to convert this table from wide to long format, since our `geom_tile()` function only works with long data frames. Instead of using `pivot_wider()` as we did to create `patterns`, we will use `pivot_longer` to create a data frame with each row corresponding to a pattern/quarter/status combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to long format\n",
    "patterns_long <- pivot_longer(patterns, names_to = 'Quarter', values_to = 'Status', -c(Pattern))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see patterns_long\n",
    "head(patterns_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to create the visualization using `geom_tile` in `ggplot`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full code for the plot\n",
    "\n",
    "levels = ordered(c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16))  # specify in which order to add the rows from our wide table (called \"patterns\") \n",
    "                                                             # we want to preserve the same ordering of rows as they are sorted in the table from highest to lowest\n",
    "\n",
    "ggplot(data = patterns_long, aes(x = Quarter, y = ordered(Pattern, levels=rev(levels)))) +    # sort y-axis according to levels specified above\n",
    "geom_tile(aes(fill = Status), colour = 'black') +                                             # fill the table with value from Status column, create black contouring\n",
    "scale_fill_brewer(palette = \"Set1\") +                                                         # specify a color palette\n",
    "theme(text=element_text(size=14,face=\"bold\")) +                                               # specify font size\n",
    "scale_x_discrete(position = 'top') +                                                          # include x-axis labels on top of the plot\n",
    "labs(\n",
    "    y = \"Employment - Percentages\",\n",
    "    title = 'Employment Patterns by Quarters',\n",
    "    caption = 'Source: KPEDS and KY UI wage records data'\n",
    ") +\n",
    "scale_y_discrete(labels=rev(pcts))  # rename the y-axis ticks to correspond to the counts from the table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also have counts on the left side of the y-axis instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full code for the plot\n",
    "\n",
    "levels = ordered(c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16))  # specify in which order to add the rows from our wide table (called \"patterns\") \n",
    "                                                             # we want to preserve the same ordering of rows as they are sorted in the table from highest to lowest\n",
    "\n",
    "ggplot(data = patterns_long, aes(x = Quarter, y = ordered(Pattern, levels=rev(levels)))) +    # sort y-axis according to levels specified above\n",
    "geom_tile(aes(fill = Status), colour = 'black') +                                             # fill the table with value from Status column, create black contouring\n",
    "scale_fill_brewer(palette = \"Set1\") +                                                         # specify a color palette\n",
    "theme(text=element_text(size=14,face=\"bold\")) +                                               # specify font size\n",
    "scale_x_discrete(position = 'top') +                                                          # include x-axis labels on top of the plot\n",
    "labs(\n",
    "    y = \"Employment - Counts\",\n",
    "    title = 'Employment Patterns by Quarters',\n",
    "    caption = 'Source: KPEDS and KY UI wage records data'\n",
    ") +                                               \n",
    "scale_y_discrete(labels=rev(counts))  # rename the y-axis ticks to correspond to the counts from the table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, this notebook only contains a few of the possible visualizations you can create using the `ggplot2` package. Luckily, the R community has created countless resources you can use for making all types of visualizations!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "adrf_r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
