{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img style=\"float: center;\" src=\"images/CI_horizontal.png\" width=\"400\">\n",
    "</center>\n",
    "<center>\n",
    "    <span style=\"font-size: 1.5em;\">\n",
    "        <a href='https://www.coleridgeinitiative.org'>Website</a>\n",
    "    </span>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> Julia Lane, Benjamin Feder, Angela Tombari, Ekaterina Levitskaya, Tian Lou, Lina Osorio-Copete. </center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are problems where there does not exist a target variable to predict, but instead we want to discover any inherent groupings or patterns in the data. Unsupervised machine learning methods can help tackle these problems. Clustering is the most common unsupervised machine learning technique, but you might also be aware of principal components analysis (PCA) or neural networks implementations such as self-organizing maps (SOM). This notebook will provide an introduction to unsupervised machine learning through a clustering example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering is used to group data points together that are similar to each other. Optimally, a given clustering method will produce groupings with high intra-cluster (within) similarity and low inter-cluster (between) similarity. Clustering algorithms typically require a distance or similarity metric to generate clusters. They take a dataset and a distance metric (and sometimes additional parameters), and they generate clusters based on that distance metric. The most common distance metric used is Euclidean distance, but other commonly-used metrics are Manhattan, Minkowski, Chebyshev, Cosine, Hamming, Pearson, and Mahalanobis.\n",
    "\n",
    "Most clustering algorithms also require the user to specify the number of clusters (or some other parameter that indirectly determines the number of clusters) in advance as a parameter. This is often difficult to do a priori and typically makes clustering an iterative and interactive task. Another aspect of clustering that makes it interactive is often the difficulty in automatically evaluating the quality of the clusters. While various analytical clustering metrics have been developed, the best clustering is task-dependent and thus must be evaluated by the user. There may be different clusterings that can be generated with the same data. You can imagine clustering similar news stories based on the topic content, writing style or sentiment. The right set of clusters depends on the user and the task at hand. Clustering is therefore typically used for exploring the data, generating clusters, exploring the clusters, and then rerunning the clustering method with different parameters or modifying the clusters (by splitting or merging the previous set of clusters). Interpreting a cluster can be nontrivial: you can look at the centroid of a cluster, look at frequency distributions of different features (and compare them to the prior distribution of each feature), or other aspects.\n",
    "\n",
    "Here, we will focus on **K-Means clustering** (*k* defines the number of clusters), which is considered to be the most commonly used clustering method. The algorithm works as follows:\n",
    "1. Select *k* (the number of clusters you want to generate).\n",
    "2. Initialize by selecting k points as centroids of the *k* clusters. This is typically done by selecting k points uniformly at random.\n",
    "3. Assign each point a cluster according to the nearest centroid.\n",
    "4. Recalculate cluster centroids based on the assignment in **(3)** as the mean of all data points belonging to that cluster.\n",
    "5. Repeat **(3)** and **(4)** until convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm stops when the assignments do not change from one iteration to the next. The final set of clusters, however, depends on the starting points. If initialized differently, it is possible that different clusters are obtained. One common practical trick is to run *k*-means several times, each with different (random) starting points. The *k*-means algorithm is fast, simple, and easy to use, and is often a good first clustering algorithm to try and see if it fits your needs. When the mean of the data points cannot be computed, a related method called *K-medoids* can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates using *k*-means clustering to better understand Kentucky's labor market in 2013Q3. We've already developed a handful of employer-level measures in a supplemental notebook. We will try a few different values of *k* to see how we can best understand the labor market by looking for differentiation between each of the clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages and Set Up\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main R package that we will use for clustering is called `cluster`. We also import all our usual packages for database connection and data manipulation/visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#database interaction imports\n",
    "library(DBI)\n",
    "library(RPostgreSQL)\n",
    "\n",
    "# for data manipulation/visualization\n",
    "library(tidyverse)\n",
    "library(ggplot2)\n",
    "\n",
    "# clustering\n",
    "library(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an RPostgreSQL driver\n",
    "drv <- dbDriver(\"PostgreSQL\")\n",
    "\n",
    "# connect to the database\n",
    "con <- dbConnect(drv,dbname = \"postgresql://stuffed.adrf.info/appliedda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read in the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will read-in a table from the database called `employers_2013` which contains characteristics of Kentucky's labor market from 2012Q4-2014Q3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read into R\n",
    "qry <- \"\n",
    "select *\n",
    "from ada_ky_20.employers_2013\n",
    "\"\n",
    "emp <- dbGetQuery(con, qry)\n",
    "\n",
    "# see employers\n",
    "head(emp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table contains information for employers by quarter. Because some employers appear in one quarter but may not appear in another quarter, for consistency, we will subset our dataframe to include information only for one quarter and one year: third quarter of 2013."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset a dataframe by rows from 2013Q3\n",
    "\n",
    "emp <- emp %>%\n",
    "    filter(qtr == 3, calendaryear == 2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that we only have 3rd quarter now\n",
    "unique(emp$qtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that we only have one year\n",
    "unique(emp$calendaryear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to remove the `employeeno` variable from our data frame since the feature does not provide any explanatory power for our k-means algorithm. Additionally, k-means algorithms only work properly with continuous features. This is because k-means calculates its distance measure using euclidean distance, which is the distance between each data point and the centroid of a cluster. It is hard to assign positions for categorical variables in the euclidean space. Thus, we also need to remove `naics` from `emp`.\n",
    "\n",
    "> There are more sophisticated clustering algorithms that do not use Euclidean distances and thus allow categorical variables in the model. If you are interested in them, you can take a look at the functions `kmodes` and `gower.dist` - you will need to download their respective libraries first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove employeeno, naics, and also quarter and calendaryear as we only have one quarter and one year\n",
    "emp_ml <- emp %>%\n",
    "    select(-c(employeeno, naics, qtr, calendaryear))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(emp_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data type of all variables - make sure all of them are numeric\n",
    "str(emp_ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It is important that we consider scaling these features** before we compute *k*-means clustering, especially if the metrics are on a variety of numerical scales. Let's see if they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get descriptions of each variable using \"summary\" function\n",
    "summary(emp_ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we have variables on different numerical scales - we can scale them using `scale()` function on our dataframe `emp_ml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "emp_ml <- scale(emp_ml)\n",
    "\n",
    "# View first rows after scaling\n",
    "head(emp_ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running a clustering algorithm, we need to make sure that there are no missing values. Here we will use `na.omit()` function which removes all rows with any NA values. (If an employer has missing information in any of the columns, a row will be dropped).\n",
    "\n",
    "> Note that you should **never remove data** if possible - in a real world setting you would likely want to fill any missing data with an imputation or baseline assumption. We will discuss missing data during the Inference session in Module 3 of the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of rows (where each row is a unique employer)\n",
    "nrow(emp_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also need to remove all missing data points before running clustering\n",
    "# na.omit will remove any rows with any NA values\n",
    "emp_ml <- na.omit(emp_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of rows after dropping rows with any NA values\n",
    "nrow(emp_ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Choose the Number of Clusters, *K*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running a *k*-means model is simple: we just need to use `kmeans()` and choose the number of clusters (called `centers`). What number should we choose? Here, we have 11 features, so it is hard to visualize the data and decide the proper number by using our eyes. Let's start with a small number, such as 3, and see how the results look like.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because *k*-means clustering will generate different results (due to different starting points), we will set a seed so that the work in this notebook can be reproducible using the `set.seed()`. To get the same results, you must use the same seed before running the clustering algorithm every time. Luckily, if you set the same seed as your collaborators and are running the same *k*-means algorithm, you will see the same results, even if you are working in different environments, i.e. Jupyter notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model and run on emp_ml\n",
    "set.seed(1)\n",
    "k3 <- kmeans(emp_ml, centers=3, nstart=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `nstart` specifies a number of initial configurations and reports on the best one - an optimal number is usually somewhere between 20 and 50. (See more information in the Resources section - Professor Steorts, Duke University)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(k3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`kmeans` function returns the following components, most useful for us:\n",
    "- `cluster` - an integer indicating a cluster to which each point is allocated\n",
    "- `centers` - a matrix of cluster centers\n",
    "- `totss` - the total sum of squares\n",
    "- `withinss` - vector of within-cluster sum of squares, one component per cluster.\n",
    "- `tot.withinss` - total within-cluster sum of squares, i.e. `sum(withinss)`\n",
    "- `betweenss` - the between-cluster sum of squares, i.e. `totss-tot.withinss`\n",
    "- `size` - the number of points in each cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the size of each cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k3$size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that most of the employers are concentrated in cluster [redacted]. In the perfect world, we would want them to be distributed more evenly across clusters, but in some cases, it may make sense that they wouldn't. Most importantly, we are looking for high intra-cluster similarity and low inter-cluster similarity.\n",
    "\n",
    "Are there major differences in the characteristics of employers in each cluster?\n",
    "\n",
    "We can take a look at basic descriptives of the employers in these clusters by adding our clustering results to the original dataframe, `emp`, and call this dataframe `frame_3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp <- na.omit(emp)                     # remove missing values\n",
    "frame_3 <- data.frame(emp, k3$cluster)  # add cluster number to the original dataframe\n",
    "frame_3 <- subset(frame_3, select= -c(employeeno,naics, qtr, calendaryear))  # remove employeeno, naics, qtr, calendaryear columns\n",
    "\n",
    "frame_3 %>%\n",
    "    group_by(k3.cluster) %>%\n",
    "    summarize_all(\"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, we can see that our biggest cluster, cluster [redacted], contains relatively [redacted] employers that pay their employees [redacted] wages. Cluster [redacted] also has relatively [redacted], but on average, they pay their employees more than [redacted] employers in cluster [redacted] and they employ more full-quarter employees than in cluster [redacted]. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate clusters\n",
    "\n",
    "One simple way to evaluate resulting clusters is to compare the summary stats between key variables of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the differences between the clusters in more detail by finding mean and standard deviation for the following variables: `avg_earnings`, `bottom_25_pctile`, and `top_25_pctile`. We will first need to convert our data frame into a long format, with each variable/cluster combination corresponding to a distinct row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(frame_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results with mean to a dataframe\n",
    "frame_3_mean <- frame_3 %>%\n",
    "    group_by(k3.cluster) %>%\n",
    "    select(c(avg_earnings, bottom_25_pctile, top_25_pctile)) %>%\n",
    "    summarize_all(mean) %>%\n",
    "    pivot_longer(-k3.cluster, names_to = \"variable\", values_to = \"mean\")\n",
    "\n",
    "# Save results with standard deviation to a dataframe\n",
    "frame_3_sd <- frame_3 %>%\n",
    "    group_by(k3.cluster) %>%\n",
    "    select(c(avg_earnings, bottom_25_pctile, top_25_pctile)) %>%\n",
    "    summarize_all(sd) %>%\n",
    "    pivot_longer(-k3.cluster, names_to = \"variable\", values_to = \"sd\") %>%\n",
    "    select(-c(k3.cluster, variable))\n",
    "\n",
    "# Bind two dataframes together\n",
    "df <- cbind(frame_3_mean,frame_3_sd)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use this data frame to visualize the means and standard deviations in our 3 clusters for these 3 variables: `avg_earnings`, `bottom_25_pctile`, and `top_25_pctile` using a bar plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(df, aes(x=k3.cluster, y=mean, fill=k3.cluster)) +\n",
    "    geom_bar(stat=\"identity\", position = position_dodge()) +    # plot bars for the mean values\n",
    "    geom_errorbar(aes(ymax= mean + sd, ymin = mean),            # add standard deviation bars\n",
    "                  width=.2,\n",
    "                  position = position_dodge(.9)) +\n",
    "    facet_grid(. ~ variable) +                                  # plot by 3 variables of interest\n",
    "    ggtitle(\"REDACTED\") +                                       # add title\n",
    "    xlab(\"Clusters\") +                                          # add label for x-axis\n",
    "    ylab(\"Mean\") +                                              # add label for y-axis\n",
    "    theme(text = element_text(size=16),                         # increase text font\n",
    "          axis.text.x = element_text(size=18, face=\"bold\"),     # increase text font on x-axis and make it bold\n",
    "          legend.position = \"none\")                             # remove legend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visulization functions\n",
    "\n",
    "We can also create a function to facilitate visualizing different columns in a similar way. The function takes the mean, standard deviation, and title of the visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save it to a dataframe\n",
    "frame_3_mean_sd <- frame_3 %>%\n",
    "    group_by(k3.cluster) %>%\n",
    "    select(c(avg_earnings, bottom_25_pctile, top_25_pctile)) %>%\n",
    "    summarise_all(funs(mean, sd))\n",
    "\n",
    "# Visualize average earnings by cluster\n",
    "viz <- function(mean, sd, title) {\n",
    "    ggplot(frame_3_mean_sd, aes(x=k3.cluster, y=mean, fill=k3.cluster)) +\n",
    "    geom_bar(position = position_dodge(), stat=\"identity\", fill=\"gray\") +\n",
    "    geom_errorbar(aes(ymax= mean + sd, ymin = mean),\n",
    "                  width=.2,\n",
    "                  position = position_dodge(.9)) +\n",
    "    ggtitle(title) +\n",
    "    xlab(\"Clusters\") +\n",
    "    ylab(\"Mean\") +\n",
    "    theme(text = element_text(size=16),\n",
    "          axis.text.x = element_text(size=18, face=\"bold\"),\n",
    "          legend.position = \"none\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz(frame_3_mean_sd$avg_earnings_mean, frame_3_mean_sd$avg_earnings_sd, \"Average Earnings: Differences between clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz(frame_3_mean_sd$bottom_25_pctile_mean, frame_3_mean_sd$bottom_25_pctile_sd, \"Bottom 25 Percentile: Differences between clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz(frame_3_mean_sd$top_25_pctile_mean, frame_3_mean_sd$top_25_pctile_sd, \"Top 25 Percentile: Differences between clusters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare industries\n",
    "\n",
    "We can also compare clusters by looking at the most common industries within each cluster. Let's read in our `naics_2012_upd` table to find the corresponding titles to these codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read naics_2012_upd table into R as dataframe naics\n",
    "qry = '\n",
    "select *\n",
    "from ada_ky_20.naics_2012_upd\n",
    "'\n",
    "naics <- dbGetQuery(con, qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_3 <- data.frame(emp, k3$cluster)  # add cluster number to the original dataframe\n",
    "\n",
    "frame_3 <- frame_3 %>%\n",
    "    group_by(k3.cluster, naics) %>%          # group by cluster and industry\n",
    "    summarise(unique_emp = n_distinct(employeeno)) %>%  \n",
    "    ungroup() %>%\n",
    "    group_by(k3.cluster) %>%\n",
    "    arrange(desc(unique_emp)) %>%        # count number of unique employers\n",
    "    slice(1:3)                           # choose top 3 industries in each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left join with industry names\n",
    "frame_3 %>% \n",
    "    left_join(naics, by=c('naics' = 'naics_us_code')) %>%\n",
    "    select(-c(seq_no,naics)) %>%\n",
    "    filter(!is.na(naics_us_title)) %>%\n",
    "    arrange(k3.cluster, desc(unique_emp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the most prominent industries in each of the clusters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do these clustering results make sense to you? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting *k*\n",
    "\n",
    "How do we know if we chose an optimal number of clusters to describe our data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elbow method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the *Elbow method* as one input in selecting the optimal cluster number. Recall that *k*-means starts with k random cluster centers (centroids), assigns each data point to the closest centroid, and calculates the distances between each point and the centroid. Then it moves the positions of the centroids and repeats the previous steps until there is convergence. In the *Elbow method*, we try different k values and calculate the sum of squared errors (`SSE`) after the model converges. Then we plot all the `SSE` by K in a line-chart. The line-chart should resemble an arm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "\n",
    "# function to compute total within-cluster sum of square\n",
    "wss <- function(k) {\n",
    "    kmeans(emp_ml, k)$tot.withinss\n",
    "}\n",
    "\n",
    "# compute and plot wss for k =1 to k = 15\n",
    "k.values <- 1:15\n",
    "\n",
    "# extract wss values for each k\n",
    "wss_values <- map_dbl(k.values, wss)\n",
    "\n",
    "# plot the resulting SSE for each value of k\n",
    "plot(k.values, wss_values, \n",
    "    type = \"b\", pch=19, frame=FALSE,\n",
    "    xlab = \"Number of clusters K\", \n",
    "    ylab = \"Total within-clusters sum of squares\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that SSE decreases as we increase k. Here, it decreases faster when k is small. As k increases, the reduction in SSE becomes smaller. We try to choose the number around the inflection point, where the change in SSE becomes negligible, indicating that there is little room to improve the model by increasing k (the bend in the elbow). On our graph, the elbow curve begins to flatten around k = 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the model with 4 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "k4 <- kmeans(emp_ml, centers = 4)\n",
    "k4$size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the cluster size with 4 clusters is more evenly distributed now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save these results to a dataframe called `frame_4`, and check characteristics of employers in each cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_4 <- data.frame(emp, k4$cluster)  # add cluster number to the original dataframe\n",
    "frame_4 <- subset(frame_4, select= -c(employeeno,naics, qtr, calendaryear))  # remove employeeno, naics, qtr, calendaryear columns\n",
    "\n",
    "frame_4 %>%\n",
    "    group_by(k4.cluster) %>%\n",
    "    summarize_all(\"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have [redacted] cluster(s) with [redacted] employers, but who do not necessarily pay the highest wages - the highest wages are in cluster [redacted], from [redacted] employers, and then we have [redacted] cluster(s) [redacted] with [redacted] employers and [redacted] wages. The difference between [redacted] employers is in the number of full-quarter employees, as well as employment, hire, and separation rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take a look at the three most prominent industries in each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read naics_2017 table into R as naics\n",
    "qry = '\n",
    "select *\n",
    "from public.naics_2017\n",
    "'\n",
    "naics <- dbGetQuery(con, qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_4 <- data.frame(emp, k4$cluster)  # add cluster number to the original dataframe\n",
    "\n",
    "frame_4 <- frame_4 %>%\n",
    "    group_by(k4.cluster, naics) %>%\n",
    "    summarise(unique_emp = n_distinct(employeeno)) %>%\n",
    "    top_n(3, unique_emp) \n",
    "\n",
    "frame_4 %>% \n",
    "    left_join(naics, by=c('naics' = 'naics_us_code')) %>%\n",
    "    select(-c(seq_no,naics))  %>%\n",
    "    arrange(k4.cluster, desc(unique_emp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which clustering results - `frame_3` or `frame_4` - do you prefer? Do you think it could be optimal to choose more clusters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, in clustering there is no single right answer - every time we run a different number of clusters, interesting patterns about our data can be exposed. However, what we do want to know is whether the clusters that we find represent true subgroups in our data. This could be a crucial input toward choosing the right number of clusters. (See more information on additional methods for selecting `k` in the Resources section - Professor Steorts, Duke University).\n",
    "\n",
    "Experiment with different numbers of clusters in the Checkpoint 1 below - given knowledge about Kentucky labor market in 2013 Q3, which number of clusters makes the most sense to you?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><h3> Checkpoint 1: Run a K-Means clustering model </h3></font> \n",
    "\n",
    "1. Take a look again at the elbow curve, which number(s) do you think is (are) optimal?\n",
    "\n",
    "2. Choose a cluster number that you think is best (other than 3 or 4). Use `kmeans()` to run a k-means clustering model with the number you choose. Save your results and features in `frame_k`. \n",
    "\n",
    "3. Compare your results with the results we got previously. Do you find any differences? Are the results improved, in your opinion?\n",
    "\n",
    "Hint: in the Elbow method graph, it looks like 11 could be another optimal cluster - you can try with 11 clusters and see the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cohort's Employers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will take a look at our cohort's employers, and identify the clusters they belong to based on the `frame_4` clustering results.\n",
    "\n",
    "> We will need to subset `df_wages` to just jobs in 2013Q3 in order to line up with these clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read earnings of cohort into R\n",
    "qry = \"\n",
    "select *\n",
    "from ada_ky_20.cohort_wages\n",
    "\"\n",
    "df_wages = dbGetQuery(con, qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique(df_wages$job_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset by 2013 Q3\n",
    "df_wages <- df_wages[which(df_wages$job_date=='2013-07-01'), ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will not subset to the dominant employer for each `coleridge_id` in `df_wages`. However, in the final section, we introduce the idea of just selecting dominant employers for each `coleridge_id` before starting a cohort-specific analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_4 <- data.frame(emp, k4$cluster)  \n",
    "\n",
    "# Join wages table with frame_4 clustering results\n",
    "df_wages <- df_wages %>%\n",
    "    inner_join(frame_4, by='employeeno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by clusters and find number of unique employers in each cluster\n",
    "df_wages %>%\n",
    "    group_by(k4.cluster) %>%\n",
    "    summarise(emp_cohort = n_distinct(employeeno))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compare what percentage of all employers in our clusters hire our cohort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of unique employers per cluster in the full dataframe (all employers)\n",
    "frame_4 %>%\n",
    "    group_by(k4.cluster) %>%\n",
    "    summarise(emp_all = n_distinct(employeeno))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cohort and all employers dataframes\n",
    "\n",
    "cohort_emp <- df_wages %>%\n",
    "    group_by(k4.cluster) %>%\n",
    "    summarise(emp_cohort = n_distinct(employeeno))\n",
    "\n",
    "emp_all <- frame_4 %>%\n",
    "    group_by(k4.cluster) %>%\n",
    "    summarise(emp_all = n_distinct(employeeno))\n",
    "\n",
    "# Join cohort employers with all employers, and find percentage\n",
    "cohort_emp %>%\n",
    "    inner_join(emp_all, by = 'k4.cluster') %>%\n",
    "    mutate(percentage = (emp_cohort / emp_all) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reminder, one limitation of our `employers_2013` file is that it doesn't include employers with less than 5 employees. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add industry names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wages_industry_names <- df_wages %>%\n",
    "    group_by(k4.cluster, naics) %>%\n",
    "    summarise(unique_emp = n_distinct(employeeno)) %>%\n",
    "    slice_max(unique_emp, n = 3) %>%\n",
    "    arrange(k4.cluster, naics) %>%\n",
    "    slice(1:3)         # for cases where there are ties, we need to use slice, to pick only top 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wages_industry_names %>% \n",
    "    left_join(naics, by=c('naics' = 'naics_us_code')) %>%\n",
    "    select(-c(seq_no,naics)) %>%\n",
    "    arrange(k4.cluster, desc(unique_emp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compare average earnings of our cohort by cluster with average earnings of all employees in each cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average earnings for KY graduates by cluster\n",
    "df_wages %>%\n",
    "    group_by(k4.cluster) %>%\n",
    "    summarise(mean_earnings_cohort = mean(wages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average earnings for all employees by cluster\n",
    "frame_4 %>%\n",
    "    group_by(k4.cluster) %>%\n",
    "    summarise(mean_earnings_all = mean(avg_earnings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><h3> Checkpoint 2: Cohort's Employers </h3></font> \n",
    "\n",
    "How are the cohort's employers distributed between clusters in other clustering models (numbers of clusters) that you tried in Checkpoint 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------\n",
    "### Code for visualizations from the ML slides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we provide the code that created visualizations for results with 11 clusters in the Machine Learning slides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Compare the mean of variables between all employers and employers in each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 11 clusters\n",
    "set.seed(1)\n",
    "k11 <- kmeans(emp_ml, centers = 11)\n",
    "k11$size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cluster assignment to the original dataframe\n",
    "frame_11 <- data.frame(emp, k11$cluster) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of unique employers by cluster\n",
    "result <- frame_11 %>%\n",
    "                group_by(k11.cluster) %>%\n",
    "                summarise(n_employers = n_distinct(employeeno))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-numerical columns\n",
    "frame_11_subset <- subset(frame_11, select = -c(employeeno, naics, qtr, calendaryear))\n",
    "\n",
    "# Get means by cluster\n",
    "cframe_cluster <- frame_11_subset  %>%\n",
    "                    group_by(k11.cluster) %>%\n",
    "                    summarise_all('mean')\n",
    "\n",
    "# Get means for all employers\n",
    "cframe_all <- frame_11_subset %>%\n",
    "                    summarise_all('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove column name with clusters\n",
    "cframe_cluster_subset <- subset(cframe_cluster, select = -c(k11.cluster))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through columns and compare means of clusters with means of all employers\n",
    "# If a mean of a variable in a cluster is higher than a mean for all employers, then add +, otherwise -\n",
    "\n",
    "for(i in names(cframe_cluster_subset)){\n",
    "    cframe_cluster_subset[,i] <- ifelse(cframe_cluster[,i] > cframe_all[,i], '+', '-')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine two tables: one with number of unique employers and with means comparison\n",
    "means_comparison <- cbind(result,cframe_cluster_subset)\n",
    "\n",
    "means_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can save a dataframe to a csv with a write_csv function\n",
    "# means_comparison %>% write_csv('/nfshome/YOURUSERNAME/means_comparison.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting table shows us a comparison between the means of variables in each cluster and the means of the same variables for all employers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Fuzzy box plot of full-quarter employees by cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe\n",
    "upd_stats <- data.frame()\n",
    "\n",
    "# Create a loop to go through each cluster\n",
    "# start of a loop:\n",
    "for(grp in unique(frame_11$k11.cluster)){\n",
    "    new_df <- frame_11 %>%\n",
    "        filter(k11.cluster == grp)\n",
    "    \n",
    "stats <- new_df %>%\n",
    "    group_by(k11.cluster) %>%\n",
    "    # find fuzzy percentiles\n",
    "    summarize(\n",
    "        'fuzzy_25' = (quantile(full_num_employed, .20) + quantile(full_num_employed, .30))/2,\n",
    "        'fuzzy_50' = (quantile(full_num_employed, .45) + quantile(full_num_employed, .55))/2,\n",
    "        'fuzzy_75' = (quantile(full_num_employed, .70) + quantile(full_num_employed, .80))/2\n",
    "        ) %>%\n",
    "   # find min and max cutoff values\n",
    "    mutate(\n",
    "        fuzzy_min_cutoff = (fuzzy_25 - 1.5*(fuzzy_75 - fuzzy_25)),\n",
    "        fuzzy_max_cutoff = (fuzzy_75 + 1.5*(fuzzy_75 - fuzzy_25))\n",
    "       )\n",
    "\n",
    "df_grp <- new_df %>%\n",
    "    filter(full_num_employed > stats[stats$k11.cluster == grp,]$fuzzy_min_cutoff, \n",
    "           full_num_employed < stats[stats$k11.cluster == grp,]$fuzzy_max_cutoff)\n",
    "\n",
    "# find fuzzy max\n",
    "new_max <- df_grp %>%\n",
    "    arrange(desc(full_num_employed)) %>%\n",
    "    head(2) %>%\n",
    "    summarize(m = mean(full_num_employed))\n",
    "\n",
    "# find fuzzy min\n",
    "new_min <- df_grp %>%\n",
    "    arrange(full_num_employed) %>%\n",
    "    head(2) %>%\n",
    "    summarize(m = mean(full_num_employed))\n",
    "\n",
    "stats<-stats %>%\n",
    "    mutate(\n",
    "        fuzzy_min = new_min$m,\n",
    "        fuzzy_max = new_max$m\n",
    "    )\n",
    "# fill upd_stats with the stats for each of the kpeds_sectors\n",
    "upd_stats <- rbind(upd_stats, stats)\n",
    "}\n",
    "# end of a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upd_stats %>%\n",
    "    ggplot(aes(x=as.character(k11.cluster), ymin = fuzzy_min, lower = fuzzy_25, middle = fuzzy_50, upper = fuzzy_75, ymax = fuzzy_max)) +\n",
    "    geom_boxplot(stat=\"identity\") + \n",
    "    labs(\n",
    "        title = 'Number of Full Quarter Employees per Employer by Cluster',\n",
    "        y = 'Number of Full Quarter Employees (log10 scale)',\n",
    "        x='Cluster',\n",
    "        caption = 'Source: KPEDS, UI Wages data'\n",
    "    ) +\n",
    "    scale_y_continuous(trans = 'log10') + \n",
    "    scale_x_discrete(limits = c(1:11)) +\n",
    "    theme_minimal() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ggsave('/nfshome/YOURUSERNAME/box_plot_full_quarter_employees.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Fuzzy box plot of average earnings per employee by cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the same loop as above - change the variable to: avg_earnings\n",
    "\n",
    "upd_stats <- data.frame()\n",
    "\n",
    "for(grp in unique(frame_11$k11.cluster)){\n",
    "    new_df <- frame_11 %>%\n",
    "        filter(k11.cluster == grp)\n",
    "    \n",
    "stats <- new_df %>%\n",
    "    group_by(k11.cluster) %>%\n",
    "    summarize(\n",
    "        'fuzzy_25' = (quantile(avg_earnings, .20) + quantile(avg_earnings, .30))/2,\n",
    "        'fuzzy_50' = (quantile(avg_earnings, .45) + quantile(avg_earnings, .55))/2,\n",
    "        'fuzzy_75' = (quantile(avg_earnings, .70) + quantile(avg_earnings, .80))/2\n",
    "        ) %>%\n",
    "   # find min and max cutoff values\n",
    "    mutate(\n",
    "        fuzzy_min_cutoff = (fuzzy_25 - 1.5*(fuzzy_75 - fuzzy_25)),\n",
    "        fuzzy_max_cutoff = (fuzzy_75 + 1.5*(fuzzy_75 - fuzzy_25))\n",
    "       )\n",
    "\n",
    "df_grp <- new_df %>%\n",
    "    filter(avg_earnings > stats[stats$k11.cluster == grp,]$fuzzy_min_cutoff, \n",
    "       avg_earnings < stats[stats$k11.cluster == grp,]$fuzzy_max_cutoff)\n",
    "\n",
    "# find fuzzy max\n",
    "new_max <- df_grp %>%\n",
    "    arrange(desc(avg_earnings)) %>%\n",
    "    head(2) %>%\n",
    "    summarize(m = mean(avg_earnings))\n",
    "\n",
    "# find fuzzy min\n",
    "new_min <- df_grp %>%\n",
    "    arrange(avg_earnings) %>%\n",
    "    head(2) %>%\n",
    "    summarize(m = mean(avg_earnings))\n",
    "\n",
    "stats<-stats %>%\n",
    "    mutate(\n",
    "        fuzzy_min = new_min$m,\n",
    "        fuzzy_max = new_max$m\n",
    "    )\n",
    "# fill upd_stats with the stats for each of the kpeds_sectors\n",
    "upd_stats <- rbind(upd_stats, stats)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upd_stats %>%\n",
    "    ggplot(aes(x=as.character(k11.cluster), ymin = fuzzy_min, lower = fuzzy_25, middle = fuzzy_50, upper = fuzzy_75, ymax = fuzzy_max)) +\n",
    "    geom_boxplot(stat=\"identity\") + \n",
    "    labs(\n",
    "        title = 'Average Earnings per Employee by Cluster',\n",
    "        y = 'Earnings',\n",
    "        x='Cluster',\n",
    "        caption = 'Source: KPEDS, UI Wages data'\n",
    "    ) +\n",
    "    scale_x_discrete(limits = c(1:11)) +\n",
    "    theme_minimal() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can save this plot by using ggsave:\n",
    "# ggsave('/nfshome/YOURUSERNAME/box_plot_average_earnings.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Compare cohort's employers and all employers in each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read earnings of cohort into R\n",
    "qry = \"\n",
    "select *\n",
    "from ada_ky_20.cohort_wages\n",
    "\"\n",
    "df_wages = dbGetQuery(con, qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset by 2013 Q3\n",
    "df_wages <- df_wages[which(df_wages$job_date=='2013-07-01'), ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset by only dominant employer (by highest wages)\n",
    "df_wages_dominant <- df_wages %>%\n",
    "                        group_by(coleridge_id) %>%\n",
    "                        top_n(1, wages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add industry names\n",
    "frame_11 <- frame_11 %>% \n",
    "    left_join(naics, by=c('naics' = 'naics_us_code')) %>%\n",
    "    select(-c(seq_no,naics))\n",
    "\n",
    "# Rename the industry column to match with the df_wages_dominant dataframe\n",
    "frame_11 <- frame_11 %>%\n",
    "                rename(industry = naics_us_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join wages table with frame_11 clustering results\n",
    "df_wages_dominant <- df_wages_dominant %>%\n",
    "    inner_join(frame_11, by=c('employeeno','industry'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dominance <- df_wages_dominant %>%\n",
    "    group_by(employeeno, k11.cluster) %>%\n",
    "    summarize(n=n()) %>%\n",
    "    ungroup() %>%\n",
    "    group_by(k11.cluster) %>%\n",
    "    mutate(prop=n/sum(n)) %>%\n",
    "    top_n(1) %>%\n",
    "    arrange(k11.cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dominance %>% write_csv('/nfshome/YOURUSERNAME/table_industries_Kentucky_dominance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns that are not needed\n",
    "df_wages_dominant_subset <- subset(df_wages_dominant, select = c(coleridge_id, employeeno, k11.cluster))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of distinct employers and individuals from the cohort by cluster\n",
    "cohort_person_employer <- df_wages_dominant_subset %>%\n",
    "    group_by(k11.cluster) %>%\n",
    "    summarise_all(\"n_distinct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_person_employer <- subset(cohort_person_employer, select = -c(k11.cluster))\n",
    "\n",
    "new_df <- cbind(result, cohort_person_employer)\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find number of unique dominant employers in the cohort\n",
    "length(unique(df_wages_dominant_subset$employeeno))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find number of unique individuals in the cohort with dominant employers\n",
    "length(unique(df_wages_dominant_subset$coleridge_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate proportions of employers and individuals\n",
    "new_df$total_cohort_emp <- [redacted]\n",
    "new_df$total_individ_cohort <- [redacted]\n",
    "new_df$percentage_emp <- (new_df$employeeno / new_df$total_cohort_emp) * 100\n",
    "new_df$percentage_indiv <- (new_df$coleridge_id / new_df$total_individ_cohort) * 100\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mean of average earnings of the cohort by cluster\n",
    "avg_earnings <- df_wages_dominant %>%\n",
    "                group_by(k11.cluster) %>%\n",
    "                summarise(mean_earnings_cohort = mean(wages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df <- left_join(new_df, avg_earnings, by='k11.cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove missing industry names\n",
    "frame_11 <- na.omit(frame_11)\n",
    "\n",
    "# Add top 3 industries by cluster\n",
    "cluster_industries <- frame_11 %>%\n",
    "    group_by(k11.cluster, industry) %>%\n",
    "    summarise(unique_emp = n_distinct(employeeno)) %>%\n",
    "    top_n(3, unique_emp) %>%\n",
    "    slice(1:3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by industry with largest number of employers first by cluster\n",
    "cluster_industries <- cluster_industries %>%\n",
    "    arrange(k11.cluster, desc(unique_emp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(reshape2)\n",
    "library(data.table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_industries <- dcast(setDT(cluster_industries), k11.cluster~rowid(k11.cluster), value.var=c('industry','unique_emp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df <- merge(new_df, cluster_industries, by='k11.cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df <- subset(new_df, select = -c(total_cohort_emp, total_individ_cohort))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can write this dataframe to a csv using write_csv function\n",
    "# new_df %>% write_csv('/nfshome/YOURUSERNAME/table_industries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.matrix.max.cols=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees <- df_wages_dominant %>%\n",
    "    group_by(k11.cluster, deg_class) %>%\n",
    "    summarise(indiv = n_distinct(coleridge_id)) %>%\n",
    "    top_n(3, indiv) %>%\n",
    "    slice(1:3) %>%\n",
    "    arrange(k11.cluster, desc(indiv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees <- dcast(setDT(degrees), k11.cluster~rowid(k11.cluster), value.var=c('deg_class','indiv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# degrees %>% write_csv('/nfshome/YOURUSERNAME/degrees.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources:\n",
    "- UC Business Analytics R Programming Guide: https://uc-r.github.io/kmeans_clustering\n",
    "- Rebecca Steorts, Assistant Professor, Duke University, Department of Statistical Science, Data Mining and Machine Learning course: https://github.com/resteorts/data-mine/tree/master/lectures_2018/10-unsupervise/10-kmeans.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "adrf_r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
