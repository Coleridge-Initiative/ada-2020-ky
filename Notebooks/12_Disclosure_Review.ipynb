{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: center;\" src=\"images/CI_horizontal.png\" width=\"600\">\n",
    "<center>\n",
    "    <span style=\"font-size: 1.5em;\">\n",
    "        <a href='https://www.coleridgeinitiative.org'>Website</a>\n",
    "    </span>\n",
    "</center>\n",
    "\n",
    "\n",
    "<div align='center'>Julia Lane, Benjamin Feder, Angie Tombari, and Ekaterina Levitskaya.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Disclosure Review Examples & Exercises_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains information on how to prepare research output for disclosure control. It outlines how to prepare different kind of outputs before submitting an export request and provides an overview of the information needed for disclosure review. _Please read through the entire notebook because it will separately discuss different types of outputs that will be flagged in the disclosure review process._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#database interaction imports\n",
    "library(DBI)\n",
    "library(RPostgreSQL)\n",
    "\n",
    "# for data manipulation/visualization\n",
    "library(tidyverse)\n",
    "\n",
    "# scaling data, calculating percentages, overriding default graphing\n",
    "library(scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an RPostgreSQL driver\n",
    "drv <- dbDriver(\"PostgreSQL\")\n",
    "\n",
    "# connect to the database\n",
    "con <- dbConnect(drv,dbname = \"postgresql://stuffed.adrf.info/appliedda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Remarks on Disclosure Review\n",
    "\n",
    "## Files you can export\n",
    "In general, any kind of file format can be exported. However, researchers typically export tables, graphs, regression outputs and aggregated data. Thus, the requirement is to export one of these types, which implies that every result designed for export needs to be saved in either .csv, .txt or graph format.\n",
    "\n",
    "## Jupyter notebooks are only exported to retrieve code\n",
    "Unfortunately, results cannot be exported in a Jupyter notebook. Doing disclosure reviews on output in Jupyter notebooks is too burdensome. Jupyter notebooks will only be exported when the output is deleted for the purpose of exporting code. **This does not mean that Jupyter notebooks will not be needed during the export process.** \n",
    "\n",
    "## Documentation of code is important\n",
    "Provide the code for every desired output for export. It is important for the ADRF staff to have the code to better understand the process for creating these outputs. Understanding how research results are created is important in understanding your research output. Thus, it is important to document every step of an analysis in a Jupyter notebook. \n",
    "\n",
    "## General rules to keep in mind\n",
    "A more detailed description of the rules for exporting results can be found on the class website. This is just a quick overview. Please go to the class website and read the entire guidelines (link below) before preparing files for export. \n",
    "- The disclosure review is based on the underlying observations of your study. **Every statistic for export must be based on at least 10 individuals. When reporting any employment statistics in Kentucky, in addition to the restriction of a minimum of 10 individuals, it must shown that 1) there are at least 10 firms and 2) employment in no one firm comprises more than 80% of the associated group to receive an export**. In other states, the statistics must be based on 3 firms and employment in no one firm comprises more than 80% of the associated group. The disclosure review team must be shown that every statistic for export is based on those numbers by providing the associated counts/percentages in an input file. \n",
    "- Document code so the reviewer can follow the data work provided. Assessing re-identification risks highly depends on the context. Therefore, it is imperative to provide context info with the analysis for the reviewer. When making a comments in the code, make sure not to use any individual statistic (e.g. the mean is ...).\n",
    "- Save the requested output with the corresponding code in the input and output folders. Make sure the code is executable. The code should exactly produce the output that is requested.\n",
    "- Please request an export only when results are final and they are needed for a presentation or final project report.\n",
    "\n",
    "## To-Do:\n",
    "Read through the **documentation** link: adrf.readthedocs.io/en/latest/export_of_results/guidelines.html#documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disclosure Review Walkthrough\n",
    "\n",
    "The statistics and visualizations created in the Data Exploration and Data Visualization notebooks will be reconstructed and prepared to pass the disclosure review process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the first guiding question in the \"Understanding Our Graduates\" [section](03_Data_Exploration.ipynb/#Understanding-Our-Graduates) of the Data Exploration notebook:\n",
    "\n",
    "- How many graduates are there by highest degree rank (within the 2013 AY)?\n",
    "\n",
    "First, the table containing the cohort must be read into R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read cohort into R\n",
    "qry <- \"\n",
    "select *\n",
    "from ada_ky_20.cohort\n",
    "\"\n",
    "df <- dbGetQuery(con, qry)\n",
    "\n",
    "# see df\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, the number of graduates by `degreerank` were found using `count()`. Because the desired statistics for export are not from any of the employment tables, the counts within all of these groups must just be at least 10. \n",
    "\n",
    "Otherwise, as mentioned above, each count would need to be comprised of at least 10 firms (in Kentucky, 3 in all other states) and that the employment in no one firm would make up more than 80% of the group to receive the export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count by degreerank\n",
    "df %>%\n",
    "    count(degreerank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `write_csv()` function will allow for the transformation of the data frame to a .csv as long as the file path and the name of the .csv are designated. Here, the file will be called `counts_by_degreerank.csv` (the more descriptive the name of the file, the easier it is for the Coleridge Initiative's export team to review).\n",
    "\n",
    "> In the file path, the `user` object is assigned to your ADRF username, the csv will be saved in the `user`'s home folder. Review the `sprintf` section in the Data Exploration [notebook](03_Data_Exploration.ipynb/#sprintf) if there is any uncertaintly around the usage of `sprintf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to your username for saving files\n",
    "user <- 'benjaminfeder'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as csv\n",
    "df %>%\n",
    "    count(degreerank) %>%\n",
    "    write_csv(sprintf('/nfshome/%s/counts_by_degreerank.csv', user))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentages\n",
    "\n",
    "A subset of working with counts, with any reported percentages, the underlying counts of the numerators and denominators must be provided for each group involved in your desired export. The following example will illustrate this notion. It is taken from the \"Understanding Our Graduates\" [section](03_Data_Exploration.ipynb/#Understanding-Our-Graduates) in the Data Exploration notebook:\n",
    "\n",
    "- What are the percentages of graduates who received their primary degrees within the seven major groups? Does this differ by institution location?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that to answer this question, `deg_class` variable in `df` was employed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see values of deg_class\n",
    "unique(df$deg_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the following code was written the find the answer to the first part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find percentage of graduates by degree type\n",
    "df %>%\n",
    "    count(deg_class) %>%\n",
    "    mutate(pct = round((n/sum(n)) * 100, 2)) %>%\n",
    "    arrange(desc(pct)) %>%\n",
    "    select(-n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how there are no counts provided in this csv. To receive this file as part of an export, a supplementary file of the counts within each of the groups must be provided. In this case, it is sufficient to `count()` the number of rows by `deg_class` to find the underlying counts for these percentages since each row in `df` corresponds to a unique individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find counts by deg_class\n",
    "df %>%\n",
    "    count(deg_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is the same denominator for this csv (total number of individuals in our cohort), an extra row for the denominator can be added using `rbind()`.\n",
    "\n",
    "> To export a table with percentages calculated as a within-row calculation by dividing two columns, the counts for the variables within each row that were used to find the percentage(s) must be provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find counts by deg_class\n",
    "df %>%\n",
    "    count(deg_class) %>%\n",
    "    rbind(data.frame(deg_class = \"total (denominator)\", n = n_distinct(df$coleridge_id)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These data frames can now be written to csv, as they are ready for export. If one file provides supporting counts and/or general information for a file designated for export, please name the supporting file `_counts` as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as csv\n",
    "df %>%\n",
    "    count(deg_class) %>%\n",
    "    mutate(pct = round((n/sum(n)) * 100, 2)) %>%\n",
    "    arrange(desc(pct)) %>%\n",
    "    select(-n) %>%\n",
    "    write_csv(sprintf('/nfshome/%s/pct_by_degree_type.csv', user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save support csv\n",
    "df %>%\n",
    "    count(deg_class) %>%\n",
    "    rbind(data.frame(deg_class = \"total (denominator)\", n = n_distinct(df$coleridge_id))) %>%\n",
    "    write_csv(sprintf('/nfshome/%s/pct_by_degree_type_counts.csv', user))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to export the percentage of graduates by `deg_class` based on their institution's location, first the institution crosswalk must be loaded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read kpeds_inst_xwalk into R\n",
    "qry <- \"\n",
    "select *\n",
    "from kystats_2020.kpeds_inst_xwalk\n",
    "\"\n",
    "inst_xwalk <- dbGetQuery(con, qry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code can be used to find the answer to the second part of this question:\n",
    "- Does this (the percentages of graduates who received their primary degrees within the seven major groups) differ by institution location?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can match on the institution code\n",
    "df_app <- df %>% \n",
    "    left_join(inst_xwalk, by=c(\"kpeds_institution\" = \"inst_code\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts of graduates by major group for colleges located in Appalachian counties\n",
    "appalachian <- df_app %>%\n",
    "    filter(appalachian == 1) %>%\n",
    "    count(deg_class) %>%\n",
    "    mutate(pct = round((n/sum(n)) * 100, 2)) %>%\n",
    "    select(-n)\n",
    "                \n",
    "\n",
    "# counts of graduates by major group for colleges located in non-Appalachian counties\n",
    "nonappalachian <- df_app %>%\n",
    "    filter(appalachian == 0) %>%\n",
    "    count(deg_class) %>%\n",
    "    mutate(pct = round((n/sum(n)) * 100, 2)) %>%\n",
    "    select(-n)\n",
    "\n",
    "#binding these two tibbles to look for differences descriptively\n",
    "cbind(appalachian %>% mutate(college_location = \"Appalachian\"), \n",
    "      nonappalachian %>% mutate(college_location = \"Non-Appalachian\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, before this data frame can be exported, it is necessary to provide the underlying counts of the numerators and denominators used to generate these percentages. The numerators can easily be found by running `count(deg_class)` after filtering by Appalachian status, and the denominators will also be added into the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find counts for appalachian\n",
    "app_counts <- df_app %>%\n",
    "    filter(appalachian == 1) %>%\n",
    "    count(deg_class) %>%\n",
    "    rbind(data.frame(deg_class = 'total (denominator)', n = n_distinct(df_app[df_app$appalachian == 1,]$coleridge_id)))\n",
    "\n",
    "# find counts for non appalachian\n",
    "nonapp_counts <- df_app %>%\n",
    "    filter(appalachian == 0) %>%\n",
    "    count(deg_class) %>%\n",
    "    rbind(data.frame(deg_class = 'total (denominator)', n = n_distinct(df_app[df_app$appalachian == 0,]$coleridge_id)))\n",
    "\n",
    "# combine the two\n",
    "cbind(app_counts %>% mutate(college_location = \"Appalachian\"), \n",
    "      nonapp_counts %>% mutate(college_location = \"Non-Appalachian\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the underlying counts are confirmed that they are all greater than 10, these data frames can be saved as csv files for export.\n",
    "\n",
    "> If some counts are less than 10, the counts should still be included as evidence in the input folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save for export\n",
    "cbind(appalachian %>% mutate(college_location = \"Appalachian\"), \n",
    "      nonappalachian %>% mutate(college_location = \"Non-Appalachian\")) %>%\n",
    "    write_csv(sprintf('/nfshome/%s/pct_by_degree_type_appalachian.csv', user))\n",
    "\n",
    "cbind(app_counts %>% mutate(college_location = \"Appalachian\"), \n",
    "      nonapp_counts %>% mutate(college_location = \"Non-Appalachian\")) %>%\n",
    "    write_csv(sprintf('/nfshome/%s/pct_by_degree_type_appalachian_counts.csv', user))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy percentiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under no circumstances will percentiles be able to be exported, regardless of if the unit of analysis is directly subject to disclosure review. To get a sense of percentiles in the data, fuzzy percentiles can be exported, which can be created by finding the average of two true percentiles. \n",
    "\n",
    "For example, a fuzzy median can be created by finding the average of the true 45th and 55th percentiles. An example of preparing data for export will be provided by walking through an another example from the Data Exploration notebooks, this time from the \"Understanding Post-Graduation In-State Employment and Earnings\" [section](03_Data_Exploration.ipynb/#Understanding-Post-Graduation-In-State-Employment-and-Earnings):\n",
    "\n",
    "- How do annual earnings post-graduation differ by degree rank?\n",
    "\n",
    "Since the cohort's earnings will be the focus of this section, the `cohort_wages` table from the `ada_ky_20` schema must be read into R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read cohort's wages into R\n",
    "qry <- \"\n",
    "select *\n",
    "from ada_ky_20.cohort_wages\n",
    "\"\n",
    "df_wages <- dbGetQuery(con, qry)\n",
    "\n",
    "# see df_wages\n",
    "head(df_wages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, to answer this question, the following code was used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more nuanced look at distribution\n",
    "df_wages %>%\n",
    "    group_by(coleridge_id, degreerank) %>%\n",
    "    summarize(total_wages = sum(wages)) %>% \n",
    "    ungroup() %>% #we ungroup to get rid of the coleridge_id variable\n",
    "    group_by(degreerank) %>% #group by only degreegroup to get us a wage summary by this variable\n",
    "    summarize('.1'  = quantile(total_wages, .1),\n",
    "              '.25' = quantile(total_wages, .25),\n",
    "              '.5'  = quantile(total_wages, .5),\n",
    "              '.75' = quantile(total_wages, .75),\n",
    "              '.9'  = quantile(total_wages, .9)\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data frame is not ready for export for four reasons:\n",
    "    \n",
    "1. These numbers represent exact percentiles and will not be accepted in the export process\n",
    "2. There are not underlying counts per each group (`degreerank` in this example)\n",
    "3. No evidence of lack of employer dominance\n",
    "4. No presence of underlying employer counts per each group\n",
    "\n",
    "This list will be followed in order. Fuzzying percentiles can be done by finding the average of our two true percentile values equidistant from the percentile in question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fuzzy quantiles\n",
    "df_wages %>%\n",
    "    group_by(coleridge_id, degreerank) %>%\n",
    "    summarize(total_wages = sum(wages)) %>% \n",
    "    ungroup() %>% #we ungroup to get rid of the coleridge_id variable\n",
    "    group_by(degreerank) %>% #group by only degreegroup to get us a wage summary by this variable\n",
    "    summarize('fuzzy 10' = (quantile(total_wages, .05) + quantile(total_wages, .15))/2,\n",
    "              'fuzzy 25' = (quantile(total_wages, .20) + quantile(total_wages, .30))/2,\n",
    "              'fuzzy 50' = (quantile(total_wages, .45) + quantile(total_wages, .55))/2,\n",
    "              'fuzzy 75' = (quantile(total_wages, .70) + quantile(total_wages, .80))/2,\n",
    "              'fuzzy 90' = (quantile(total_wages, .80) + quantile(total_wages, .95))/2\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fuzzy percentiles have been successfully found for the desired outputs. To finalize this aspect of the export, the underlying counts within each of the groups must be added, which can easily be done by adding `n()` to the `summarize()` call, since each row corresponds to a unique `coleridge_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fuzzy quantiles with counts\n",
    "df_wages %>%\n",
    "    group_by(coleridge_id, degreerank) %>%\n",
    "    summarize(total_wages = sum(wages)) %>% #this gets us up to the code used above\n",
    "    ungroup() %>% #we ungroup to get rid of the coleridge_id variable\n",
    "    group_by(degreerank) %>% #group by only degreegroup to get us a wage summary by this variable\n",
    "    summarize('fuzzy 10' = (quantile(total_wages, .05) + quantile(total_wages, .15))/2,\n",
    "              'fuzzy 25' = (quantile(total_wages, .20) + quantile(total_wages, .30))/2,\n",
    "              'fuzzy 50' = (quantile(total_wages, .45) + quantile(total_wages, .55))/2,\n",
    "              'fuzzy 75' = (quantile(total_wages, .70) + quantile(total_wages, .80))/2,\n",
    "              'fuzzy 90' = (quantile(total_wages, .8) + quantile(total_wages, .95))/2,\n",
    "              n = n()\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the underlying counts of individuals in the same data frame we would like to export have been provided, it is not necessary to additionally export a data frame of the underlying counts per group. However, because this export concerns earnings and employment data in Kentucky, there must be evidence of at least ten employers that constitute the wage calculations within each group, as well as a lack of single-employer dominance, to receive the export. Employer dominance can be defined as an employer providing at least 80 percent of the weight in the calculation. Therefore, if a group's employment relies on that ratio or greater from one employer, the group will need to be redacted.\n",
    "\n",
    "The number of employers involved in the calculations by group will be found first (still `degreerank` in this example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see number of employers per group\n",
    "df_wages %>% \n",
    "    group_by(degreerank) %>%\n",
    "    summarize(\n",
    "        n_employers = n_distinct(employeeno)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to verify the lack of employer dominance within any of the groups, the following steps can be worked through:\n",
    "- Count the instances of the employers within each `degreerank` (grouping variable)\n",
    "- Use `group_by()` to group the grouping variable\n",
    "- Calculate the proportion of entries per grouping variable for each employer\n",
    "- Select the most common employer using `top_n()`\n",
    "\n",
    "> In this case, the variable on which `top_n()` will be sorted by does not need to be specified because sorting by `n` or `prop` in this example will yield the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see employer dominance per group\n",
    "df_wages %>% \n",
    "    count(degreerank, employeeno) %>%\n",
    "    group_by(degreerank) %>%\n",
    "    mutate(prop = n/sum(n)) %>%\n",
    "    top_n(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that high enough individual counts within each group have been verified, fuzzy percentiles have been created, and the employers of these individuals have been analyzed, the data frame in question can be simply exported by piping the output into `write_csv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as csv\n",
    "df_wages %>%\n",
    "    group_by(coleridge_id, degreerank) %>%\n",
    "    summarize(total_wages = sum(wages)) %>% \n",
    "    ungroup() %>% #we ungroup to get rid of the coleridge_id variable\n",
    "    group_by(degreerank) %>% #group by only degreegroup to get us a wage summary by this variable\n",
    "    summarize('fuzzy 10' = (quantile(total_wages, .05) + quantile(total_wages, .15))/2,\n",
    "              'fuzzy 25' = (quantile(total_wages, .20) + quantile(total_wages, .30))/2,\n",
    "              'fuzzy 50' = (quantile(total_wages, .45) + quantile(total_wages, .55))/2,\n",
    "              'fuzzy 75' = (quantile(total_wages, .70) + quantile(total_wages, .80))/2,\n",
    "              'fuzzy 90' = (quantile(total_wages, .80) + quantile(total_wages, .95))/2,\n",
    "              n = n()\n",
    "             ) %>%\n",
    "    write_csv(sprintf('/nfshome/%s/fuzzy_wages_by_group.csv', user))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corresponding employer counts and dominance tests will be saved for export as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save employer dominance per group\n",
    "df_wages %>% \n",
    "    count(degreerank, employeeno) %>%\n",
    "    group_by(degreerank) %>%\n",
    "    mutate(prop = n/sum(n)) %>%\n",
    "    top_n(1) %>%\n",
    "    write_csv(sprintf('/nfshome/%s/fuzzy_wages_by_group_employer_dominance.csv', user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save number of employers per group\n",
    "df_wages %>% \n",
    "    group_by(degreerank) %>%\n",
    "    summarize(\n",
    "        n_employers = n_distinct(employeeno)\n",
    "    ) %>%\n",
    "    write_csv(sprintf('/nfshome/%s/fuzzy_wages_by_group_employer_counts.csv', user))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same disclosure controls covered up to this point for counts and other statistics apply for visualizations too, as underlying counts by groups for each visualization must be provided. The examples below are based on those from the Data Visualization notebook. The first example covered is a boxplot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplots\n",
    "\n",
    "Disclosure-proofing boxplots can be quite tricky since there are restrictions against exporting a boxplot with true percentiles or outlines. Instead, the boxplot must be created using fuzzy percentiles by user-inputting fuzzy values. This example is modified from the [Fuzzy Percentiles](Disclosure_Review.ipynb/#Fuzzy-percentiles) section above:\n",
    "\n",
    "- Creating a boxplot of the distribution of earnings for the cohort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the elements required in creating a safe boxplot:\n",
    "\n",
    "- fuzzy 25th percentile\n",
    "- fuzzy 75th percentile\n",
    "- fuzzy median (50th percentile)\n",
    "- fuzzy minimum\n",
    "- fuzzy maximum\n",
    "- no outliers\n",
    "\n",
    "These separate components of the boxplot (outside of the no outliers) can be manually inputted into the `ggplot(aes()` call. Therefore, a data frame will be created containing each of these components, and then piped it into `ggplot()` accordingly. First, the fuzzy 25th, 50th and 75th percentiles must be generated. In this example, they will all be saved to `stats`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find 25, 50 and 75 fuzzy percentiles\n",
    "stats<-df_wages %>%\n",
    "    group_by(coleridge_id) %>%\n",
    "    summarize(total_wages = sum(wages)) %>%\n",
    "    summarize(\n",
    "        'fuzzy_25' = (quantile(total_wages, .20) + quantile(total_wages, .30))/2,\n",
    "        'fuzzy_50' = (quantile(total_wages, .45) + quantile(total_wages, .55))/2,\n",
    "        'fuzzy_75' = (quantile(total_wages, .70) + quantile(total_wages, .80))/2\n",
    "        )\n",
    "# see stats\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To handle fuzzy minimum and maximum values, _first_, the cutoff values will be calculated (in both directions) to determine if an individual would be viewed as an outlier by total wages. _Second_, all individuals whose total wages are outside of this bound will be `filter()`ed out , and then _third_, and finally, the average of the individuals with the lowest and the highest wages within this bound will be taken to find the fuzzy minimum and maximum values, respectively.\n",
    "\n",
    "As the first step is completed, the fuzzy minimum and maximum values will be added to `stats` so they can be easily referred to in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find minimum and maximum cutoff values\n",
    "stats <- stats %>%\n",
    "    mutate(\n",
    "        fuzzy_min_cutoff = (fuzzy_25 - 1.5*(fuzzy_75 - fuzzy_25)),\n",
    "        fuzzy_max_cutoff = (fuzzy_75 + 1.5*(fuzzy_75 - fuzzy_25))\n",
    "    )\n",
    "# see stats\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the original data frame, `df_wages %>% group_by(coleridge_id) %>% summarize(total_wages = sum(wages))`, will be filtered to only include individuals whose counts remain within the `fuzzy_min_cutoff` and `fuzzy_max_cutoff` values. This data frame will be named `new_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find df with no outliers as per fuzzy min and max cutoffs\n",
    "new_df <- df_wages %>%\n",
    "    group_by(coleridge_id) %>%\n",
    "    summarize(total_wages = sum(wages)) %>%\n",
    "    filter((total_wages > stats$fuzzy_min_cutoff) & (total_wages < stats$fuzzy_max_cutoff)) %>%\n",
    "    ungroup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the `fuzzy_min` and `fuzzy_max` values will be found by taking the average of the two individuals with the lowest, as well as the two individuals with the highest, wages in `new_df`. These values will be saved as variables in `stats`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find fuzzy max\n",
    "new_max <- new_df %>%\n",
    "    arrange(desc(total_wages)) %>%\n",
    "    head(2) %>%\n",
    "    summarize(m = mean(total_wages))\n",
    "\n",
    "# find fuzzy min\n",
    "new_min <- new_df %>%\n",
    "    arrange(total_wages) %>%\n",
    "    head(2) %>%\n",
    "    summarize(m = mean(total_wages))\n",
    "\n",
    "# save fuzzy_min and fuzzy_max to stats\n",
    "stats <- stats %>%\n",
    "    mutate(\n",
    "        fuzzy_min = new_min$m,\n",
    "        fuzzy_max = new_max$m\n",
    "    )\n",
    "# see stats\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, `stats` can be piped into the `ggplot()` call, feeding in everything besides the `fuzzy_min_cutoff` and `fuzzy_max_cutoff` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats %>%    \n",
    "    ggplot(aes(x=\"\", ymin = fuzzy_min, lower = fuzzy_25, middle = fuzzy_50, upper = fuzzy_75, ymax = fuzzy_max)) +\n",
    "    geom_boxplot(stat=\"identity\") +\n",
    "    labs(\n",
    "        title = 'Most individuals in the cohort earned within [redacted] and [redacted] dollars in the \\n year after graduation',\n",
    "        y = 'Total Wages',\n",
    "        x='',\n",
    "        caption = 'Source: KPEDS and KY UI wage records data'\n",
    "    ) +\n",
    "    theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, in combining code all together, it would look like the code cell below.\n",
    "\n",
    "> `ggsave()` was added at the end, as it will allow for the saving of the most recent visualization to a PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make fuzzy boxplot\n",
    "# get fuzzy 25, 50, 75 and min/max cutoffs\n",
    "# find 25, 50 and 75 fuzzy percentiles\n",
    "stats<-df_wages %>%\n",
    "    group_by(coleridge_id) %>%\n",
    "    summarize(total_wages = sum(wages)) %>%\n",
    "    summarize(\n",
    "        'fuzzy_25' = (quantile(total_wages, .20) + quantile(total_wages, .30))/2,\n",
    "        'fuzzy_50' = (quantile(total_wages, .45) + quantile(total_wages, .55))/2,\n",
    "        'fuzzy_75' = (quantile(total_wages, .70) + quantile(total_wages, .80))/2\n",
    "        ) %>%\n",
    "    # find min and max cutoff values\n",
    "   mutate(\n",
    "        fuzzy_min_cutoff = (fuzzy_25 - 1.5*(fuzzy_75 - fuzzy_25)),\n",
    "        fuzzy_max_cutoff = (fuzzy_75 + 1.5*(fuzzy_75 - fuzzy_25))\n",
    "    )\n",
    "# find df with no outliers as per fuzzy min and max cutoffs\n",
    "new_df <- df_wages %>%\n",
    "    group_by(coleridge_id) %>%\n",
    "    summarize(total_wages = sum(wages)) %>%\n",
    "    filter((total_wages > stats$fuzzy_min_cutoff) & (total_wages < stats$fuzzy_max_cutoff)) %>%\n",
    "    ungroup()\n",
    "\n",
    "# find fuzzy max\n",
    "new_max <- new_df %>%\n",
    "    arrange(desc(total_wages)) %>%\n",
    "    head(2) %>%\n",
    "    summarize(m = mean(total_wages))\n",
    "\n",
    "# find fuzzy min\n",
    "new_min <- new_df %>%\n",
    "    arrange(total_wages) %>%\n",
    "    head(2) %>%\n",
    "    summarize(m = mean(total_wages))\n",
    "\n",
    "# plot same graph\n",
    "stats %>%\n",
    "    mutate(\n",
    "        fuzzy_min = new_min$m,\n",
    "        fuzzy_max = new_max$m\n",
    "    ) %>%\n",
    "    ggplot(aes(x=\"\", ymin = fuzzy_min, lower = fuzzy_25, middle = fuzzy_50, upper = fuzzy_75, ymax = fuzzy_max)) +\n",
    "    geom_boxplot(stat=\"identity\") +\n",
    "    labs(\n",
    "        title = 'Most individuals in the cohort earned within [redacted] and [redacted] dollars in the \\n year after graduation',\n",
    "        y = 'Total Wages',\n",
    "        x='',\n",
    "        caption = 'Source: KPEDS and KY UI wage records data'\n",
    "    ) +\n",
    "    theme_minimal()\n",
    "\n",
    "# save plot\n",
    "ggsave(sprintf(\"/nfshome/%s/fuzzy_boxplot_grad_earnings.pdf\", user))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the visualization uses individuals from Kentucky's UI wage records, input files containing underlying people counts, as well as underlying employer counts and lack of employer dominance must be added. The number of underlying employers and individuals can be found using `n_distinct()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of individuals\n",
    "df_wages %>%\n",
    "    summarize(n_individuals = n_distinct(coleridge_id)) %>%\n",
    "    write_csv('/nfshome/%s/fuzzy_boxplot_grad_earnings_num_individuals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of employers\n",
    "df_wages %>%\n",
    "    summarize(n_employers = n_distinct(employeeno)) %>%\n",
    "    write_csv('/nfshome/%s/fuzzy_boxplot_grad_earnings_num_employers.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find evidence of the potential lack of employer dominance, the number of rows pertaining to each employer can be counted, and then the relative proportion can be added in using `mutate()`. To find the highest proportion of rows pertaining to a single `employeeno`, the `top_n()` function can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proof of lack of employer dominance\n",
    "df_wages %>%\n",
    "    count(employeeno) %>%\n",
    "    mutate(prop = n/sum(n)) %>%\n",
    "    top_n(1) %>%\n",
    "    write_csv('/nfshome/%s/fuzzy_boxplot_grad_earnings_employer_dominance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example can be continued to look at the wage distribution after grouping the institutions of graduation by their sector. The `kpeds_sector` values need to be updated first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update kpeds_sector\n",
    "df_wages <- df_wages %>%\n",
    "    mutate(kpeds_sector = ifelse(kpeds_sector == \"AIKCU\", \"4 year independent\", kpeds_sector))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output will be transformed so it is completely disclosure-proofed. A similar structure can be followed as before, except this time, every variable included in `stats` will be done so inside a `for()` loop by each potential grouping within `kpeds_sector`, where the `stats` will be found for each value of `kpeds_sector`, and then these values can be `rbind()`ed together for each `kpeds_sector` in the last step of the `for()` loop. At the end, the output of `upd_stats` will be printed, and it contains fuzzy minimums, maximums, 25th, 50th, and 75th percentiles for each value of `kpeds_sector`.\n",
    "\n",
    "> For disclosure-proofing boxplots, the code cell below can be updated to fit your requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize data frame\n",
    "upd_stats <- data.frame()\n",
    "\n",
    "# go through each of the different sectors (groups)\n",
    "for(grp in unique(df$kpeds_sector)){\n",
    "    new_df <- df_wages %>%\n",
    "        group_by(coleridge_id, kpeds_sector) %>%\n",
    "        summarize(total_wages = sum(wages)) %>%\n",
    "        ungroup() %>%\n",
    "        filter(kpeds_sector == grp)\n",
    "\n",
    "    stats <- new_df %>%\n",
    "        group_by(kpeds_sector) %>% # the grouping variable\n",
    "        summarize(\n",
    "            'fuzzy_25' = (quantile(total_wages, .20) + quantile(total_wages, .30))/2,\n",
    "            'fuzzy_50' = (quantile(total_wages, .45) + quantile(total_wages, .55))/2,\n",
    "            'fuzzy_75' = (quantile(total_wages, .70) + quantile(total_wages, .80))/2\n",
    "            ) %>%\n",
    "       # find min and max cutoff values\n",
    "        mutate(\n",
    "            fuzzy_min_cutoff = (fuzzy_25 - 1.5*(fuzzy_75 - fuzzy_25)),\n",
    "            fuzzy_max_cutoff = (fuzzy_75 + 1.5*(fuzzy_75 - fuzzy_25))\n",
    "           )\n",
    "\n",
    "    df_grp <- new_df %>%\n",
    "        filter(total_wages > stats[stats$kpeds_sector == grp,]$fuzzy_min_cutoff, \n",
    "           total_wages < stats[stats$kpeds_sector == grp,]$fuzzy_max_cutoff)\n",
    "\n",
    "    # find fuzzy max\n",
    "    new_max <- df_grp %>%\n",
    "        arrange(desc(total_wages)) %>%\n",
    "        head(2) %>%\n",
    "        summarize(m = mean(total_wages))\n",
    "\n",
    "    # find fuzzy min\n",
    "    new_min <- df_grp %>%\n",
    "        arrange(total_wages) %>%\n",
    "        head(2) %>%\n",
    "        summarize(m = mean(total_wages))\n",
    "\n",
    "    stats<-stats %>%\n",
    "        mutate(\n",
    "            fuzzy_min = new_min$m,\n",
    "            fuzzy_max = new_max$m\n",
    "        )\n",
    "    # fill upd_stats with the stats for each of the kpeds_sectors\n",
    "    upd_stats <- rbind(upd_stats, stats)\n",
    "    }\n",
    "\n",
    "\n",
    "print(upd_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, `upd_stats` can be piped into the `ggplot()` call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upd_stats %>%    \n",
    "    ggplot(aes(x=kpeds_sector, ymin = fuzzy_min, lower = fuzzy_25, middle = fuzzy_50, upper = fuzzy_75, ymax = fuzzy_max)) +\n",
    "    geom_boxplot(stat=\"identity\") + \n",
    "    labs(\n",
    "        title = 'Graduates from [REDACTED] tend to earn REDACTED in their first year \\n after graduation',\n",
    "        y = 'Total Earnings',\n",
    "        x='Institution Type',\n",
    "        caption = 'Source: KPEDS and KY UI wage records data'\n",
    "    ) +\n",
    "    theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This figure can be saved once again using `ggsave()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggsave(sprintf('/nfshome/%s/fuzzy_boxplot_grad_earnings_by_sector.pdf', user))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before finishing this example, underlying individual counts, employer counts, and evidence of a lack of employer dominance must be provided within each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of individuals\n",
    "df_wages %>%\n",
    "    group_by(kpeds_sector) %>% \n",
    "    summarize(n_individuals = n_distinct(coleridge_id)) %>%\n",
    "    write_csv('/nfshome/%s/fuzzy_boxplot_grad_earnings_by_sector_individual_counts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of employers\n",
    "df_wages %>%\n",
    "    group_by(kpeds_sector) %>%\n",
    "    summarize(n_employers = n_distinct(employeeno)) %>%\n",
    "    write_csv('/nfshome/%s/fuzzy_boxplot_grad_earnings_by_sector_employer_counts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proof of lack of employer dominance\n",
    "df_wages %>%\n",
    "    count(employeeno, kpeds_sector) %>%\n",
    "    group_by(kpeds_sector) %>%\n",
    "    mutate(prop = n/sum(n)) %>%\n",
    "    top_n(1) %>% \n",
    "    write_csv('/nfshome/%s/fuzzy_boxplot_grad_earnings_by_sector_employer_dominance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram\n",
    "\n",
    "The thought process behind exporting histograms is very similar to the ones for other visualizations, as there must be verification that each group (or bin, in this case) follows the disclosure review guidelines. While this may seem like a simple idea, it can sometimes require a bit of manipulation.\n",
    "\n",
    "This example will walk through preparing a histogram of the distribution of wages within the cohort for export, starting with the default settings of `geom_histogram()`.\n",
    "\n",
    "> Note: In using a density plot, there is no requirement to provide counts per bin because there are no bins - the underlying counts per line just need to be included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default geom_histogram settings\n",
    "df_wages %>%\n",
    "    group_by(coleridge_id) %>%\n",
    "    summarize(total_wages = sum(wages)) %>%\n",
    "    ungroup() %>%\n",
    "    ggplot(aes(x=total_wages)) +\n",
    "    geom_histogram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the count is naturally displayed on the vertical axis, the counts within each bin may not always be clear. The `stat_bin()` layer can be added to `geom_histogram()` to display the counts per bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying counts per bin\n",
    "df_wages %>%\n",
    "    group_by(coleridge_id) %>%\n",
    "    summarize(total_wages = sum(wages)) %>%\n",
    "    ungroup() %>%\n",
    "    ggplot(aes(x=total_wages)) +\n",
    "    geom_histogram() + \n",
    "    stat_bin(aes(y=..count.., label= ..count..), geom=\"text\", vjust = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is obvious that these bins do not all have at least 10 observations. Although this issue can be solved in a variety of ways, in this notebook, the edges of the bins will be manually adjusted. To start, the code below creates a bin for every [REDACTED] dollars using the `seq()` function. \n",
    "\n",
    "> Note: The `breaks` argument must be added to both the `geom_histogram()` and then `stat_bin()` calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying counts per bin\n",
    "df_wages %>%\n",
    "    group_by(coleridge_id) %>%\n",
    "    summarize(total_wages = sum(wages)) %>%\n",
    "    ungroup() %>%\n",
    "    ggplot(aes(x=total_wages)) +\n",
    "    geom_histogram(breaks = seq(REDACTED)) +\n",
    "    stat_bin(aes(y=..count.., label= ..count..), geom=\"text\", vjust = 0, breaks = seq(REDACTED))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since each bin consists of at least 10 observations, ordinally, this visualization can be saved for export using `ggsave()`. However, since the example leverages Kentucky UI wage records, the underlying number of employers, as well as a lack of employer dominance must be shown. In this case, due to need to encode these groups, that task may be arduous. Instead, it may be easier to use a density plot to best represent the general distribution, as the number of individuals, number of employers, and lack of employer dominance just needs to be displayed for the entire sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying counts as a density plot to prevent disclosure issues\n",
    "df_wages %>%\n",
    "    group_by(coleridge_id) %>%\n",
    "    summarize(total_wages = sum(wages)) %>%\n",
    "    ungroup() %>%\n",
    "    ggplot(aes(x=total_wages)) +\n",
    "    geom_density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save viz for export\n",
    "ggsave(sprintf('/nfshome/%s/wage_distribution_density.pdf', user))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same code as in the first fuzzy boxplot export can be used as evidence for the required counts and dominance proofing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of individuals\n",
    "df_wages %>%\n",
    "    summarize(n_individuals = n_distinct(coleridge_id)) %>%\n",
    "    write_csv('/nfshome/%s/wage_distribution_density_num_individuals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of employers\n",
    "df_wages %>%\n",
    "    summarize(n_employers = n_distinct(employeeno)) %>%\n",
    "    write_csv('/nfshome/%s/wage_distribution_density_num_employers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proof of lack of employer dominance\n",
    "df_wages %>%\n",
    "    count(employeeno) %>%\n",
    "    mutate(prop = n/sum(n)) %>%\n",
    "    top_n(1) %>%\n",
    "    write_csv('/nfshome/%s/wage_distribution_density_employer_dominance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of preparing a barplot for disclosure review using wage record data is shown below, it may be useful to recall the example in the Data Visualization [notebook](05_Data_Visualization.ipynb/#Key-Sectors-by-Institution-Location) of visualizing the percentage of graduates in key sectors by Appalachian status. The original visualization (created with the code below) will be prepared for export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add in five key sectors\n",
    "# changed names a bit for viz\n",
    "df_wages <- df_wages %>%\n",
    "    mutate(key_sect = case_when(\n",
    "        majorindustry == \"Manufacturing\" ~ \"Manufacturing\",\n",
    "        majorindustry == \"Construction\" ~ \"Construction\",\n",
    "        majorindustry == \"Health Care and Social Assistance\" ~ \"Health Sciences\",\n",
    "        majorindustry == \"Transportation and Warehousing\" ~ \"Transportation\",\n",
    "        majorindustry %in% c(\"Professional, Scientific, and Technical Services\",\n",
    "                             \"Finance and Insurance\", \n",
    "                             \"Information\",\n",
    "                             \"Wholesale Trade\") ~ \"Business\",\n",
    "        TRUE ~ \"Non_Key\"\n",
    "    )\n",
    "          )\n",
    "# can match on the institution code\n",
    "df_wages_app <- df_wages %>% \n",
    "    left_join(inst_xwalk, by=c(\"kpeds_institution\" = \"inst_code\"))\n",
    "\n",
    "# find breakdown of employed graduates in KY by appalachian status of institution\n",
    "app_break<-df_wages_app %>% \n",
    "    group_by(appalachian) %>%\n",
    "    summarize(n_total=n_distinct(coleridge_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar plot of percentages by industry and appalachian status\n",
    "df_wages_app %>%\n",
    "    group_by(key_sect, appalachian) %>%\n",
    "    summarize(n = n_distinct(coleridge_id)) %>%\n",
    "    ungroup() %>%\n",
    "    left_join(app_break, \"appalachian\") %>%\n",
    "    mutate(pct = (n/n_total)*100) %>%    \n",
    "    ggplot(aes(x=word(key_sect, 1), y=pct, fill=as.factor(appalachian))) +\n",
    "    geom_bar(stat=\"identity\", position=position_dodge()) +\n",
    "    labs(\n",
    "        title = 'Graduates from Appalachian Institutions were more likely to end up in [redacted] or \\n a [redacted] sector',\n",
    "        y = 'Percentage of graduates',\n",
    "        x='Sector',\n",
    "        fill = 'Appalachian Status',\n",
    "        caption = 'Source: KPEDS and KY UI wage records data'\n",
    "    ) +\n",
    "    theme_minimal() +\n",
    "    ylim(0,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above visualization cannot be exported just yet for the following reasons:\n",
    "- No counts of numerators\n",
    "- No counts of denominators\n",
    "- Because this visualization is using Kentucky's UI wage records, proof that each numerator and denominator is associated with at least 10 employers, as well as proof of the lack of employer dominance within each group must be shown\n",
    "\n",
    "The counts for the numerators and denominators by group (`key_sect` and `appalachian`) will be found first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of individuals who were employed by sector and institution location can be found simply by counting the number of individuals within each `key_sect`, `appalachian` group. These groups must all contain at least 10 members of our cohort to proceed accordingly.\n",
    "\n",
    "> `count()` cannot be used here since each row does not correspond to one graduate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts of key_sect/appalachian combination\n",
    "df_wages_app %>%\n",
    "    group_by(key_sect, appalachian) %>%\n",
    "    summarize(n=n_distinct(coleridge_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, the counts of the denominators must be added for each of these calculations - the total number of appalachian and non-appalachian graduates.\n",
    "\n",
    "> The number and the names of the columns in `df_wages_app %>% group_by(appalachian) %>% summarize(n=n_distinct(coleridge_id))` must be identical to those of the data frames added in using `rbind()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts of deg_class/appalachian combination with totals\n",
    "df_wages_app %>%\n",
    "    group_by(key_sect, appalachian) %>%\n",
    "    summarize(n=n_distinct(coleridge_id)) %>%\n",
    "    ungroup() %>%\n",
    "    rbind(data.frame(key_sect = 'Total', appalachian = 0, n = (df_wages_app %>% group_by(appalachian) %>% summarize(n=n_distinct(coleridge_id)) %>% filter(appalachian == 0))$n),\n",
    "          data.frame(key_sect = 'Total', appalachian = 1, n = (df_wages_app %>% group_by(appalachian) %>% summarize(n=n_distinct(coleridge_id)) %>% filter(appalachian == 1))$n)\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the number for the total does not equal the sum of the counts per subgroup...and that makes sense in this example, as some individuals may have worked in multiple sectors within this time frame.\n",
    "\n",
    "The final portion of information required before exporting the visualization is at the employer level, both in terms of counts and dominance. The counts of the employers per group can be found using a similar process as the one for finding the number of graduates per group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find number of employers per group\n",
    "df_wages_app %>%\n",
    "    group_by(key_sect, appalachian) %>%\n",
    "    summarize(n=n_distinct(employeeno))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of total employers for graduates of institutions in each geographic location should be added as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of employers per group and total\n",
    "df_wages_app %>%\n",
    "    group_by(key_sect, appalachian) %>%\n",
    "    summarize(n=n_distinct(employeeno)) %>%\n",
    "    ungroup() %>%\n",
    "    rbind(data.frame(key_sect = 'Total', appalachian = 0, n = (df_wages_app %>% group_by(appalachian) %>% summarize(n=n_distinct(employeeno)) %>% filter(appalachian == 0))$n),\n",
    "          data.frame(key_sect = 'Total', appalachian = 1, n = (df_wages_app %>% group_by(appalachian) %>% summarize(n=n_distinct(employeeno)) %>% filter(appalachian == 1))$n)\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before this visualization is fully prepared for export, there must be evidence of a lack of employer dominance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# employer dominance by group\n",
    "df_wages_app %>%\n",
    "    count(key_sect, appalachian, employeeno) %>% \n",
    "    group_by(key_sect, appalachian) %>%\n",
    "    mutate(prop = n/sum(n)) %>%\n",
    "    top_n(1) %>%\n",
    "    select(-c(employeeno, n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To finish this portion of the export process, the maximum employer dominance for all of the sectors when broken down by appalachian status must be added. First, for readability purposes, this information will be assigned `emp_dom` before it is added into the original data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# employer dominance of totals\n",
    "emp_dom <- df_wages_app %>%\n",
    "    count(appalachian, employeeno) %>% \n",
    "    group_by(appalachian) %>%\n",
    "    mutate(prop = n/sum(n)) %>%\n",
    "    top_n(1) %>%\n",
    "    select(-c(employeeno, n)) %>%\n",
    "    ungroup()\n",
    "\n",
    "emp_dom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add in total group employer dominance\n",
    "df_wages_app %>%\n",
    "    count(key_sect, appalachian, employeeno) %>% \n",
    "    group_by(key_sect, appalachian) %>%\n",
    "    mutate(prop = n/sum(n)) %>%\n",
    "    top_n(1) %>%\n",
    "    ungroup() %>%\n",
    "    select(-c(employeeno, n)) %>%\n",
    "    rbind(\n",
    "        data.frame(key_sect = as.character(\"Total\"), appalachian = 0, prop = (emp_dom %>% filter(appalachian == 0))$prop),\n",
    "        data.frame(key_sect = as.character(\"Total\"), appalachian = 1, prop = (emp_dom %>% filter(appalachian == 1))$prop)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all of counts of individuals and employers are at least 10 for each subgroup and there is no employer dominance within any of the subgroups, this visualization will pass disclosure review. To finish it off, these outputs will all be saved in their respective file formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts of deg_class/appalachian combination with totals\n",
    "df_wages_app %>%\n",
    "    group_by(key_sect, appalachian) %>%\n",
    "    summarize(n=n_distinct(coleridge_id)) %>%\n",
    "    ungroup() %>%\n",
    "    rbind(data.frame(key_sect = 'Total', appalachian = 0, n = (df_wages_app %>% group_by(appalachian) %>% summarize(n=n_distinct(coleridge_id)) %>% filter(appalachian == 0))$n),\n",
    "          data.frame(key_sect = 'Total', appalachian = 1, n = (df_wages_app %>% group_by(appalachian) %>% summarize(n=n_distinct(coleridge_id)) %>% filter(appalachian == 1))$n)\n",
    "         ) %>%\n",
    "        write_csv(sprintf('/nfshome/%s/appalachian_sector_barplot_individual_counts.csv', user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write number of employers to csv\n",
    "df_wages_app %>%\n",
    "    group_by(key_sect, appalachian) %>%\n",
    "    summarize(n=n_distinct(employeeno)) %>%\n",
    "    ungroup() %>%\n",
    "    rbind(data.frame(key_sect = 'Total', appalachian = 0, n = (df_wages_app %>% group_by(appalachian) %>% summarize(n=n_distinct(employeeno)) %>% filter(appalachian == 0))$n),\n",
    "          data.frame(key_sect = 'Total', appalachian = 1, n = (df_wages_app %>% group_by(appalachian) %>% summarize(n=n_distinct(employeeno)) %>% filter(appalachian == 1))$n)\n",
    "          ) %>%\n",
    "        write_csv(sprintf('/nfshome/%s/appalachian_sector_barplot_emp_counts.csv', user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write employer dominance to csv\n",
    "df_wages_app %>%\n",
    "    count(key_sect, appalachian, employeeno) %>% \n",
    "    group_by(key_sect, appalachian) %>%\n",
    "    mutate(prop = n/sum(n)) %>%\n",
    "    top_n(1) %>%\n",
    "    ungroup() %>%\n",
    "    select(-c(employeeno, n)) %>%\n",
    "    rbind(\n",
    "        data.frame(key_sect = as.character(\"Total\"), appalachian = 0, prop = (emp_dom %>% filter(appalachian == 0))$prop),\n",
    "        data.frame(key_sect = as.character(\"Total\"), appalachian = 1, prop = (emp_dom %>% filter(appalachian == 1))$prop)\n",
    "    ) %>%\n",
    "    write_csv(sprintf('/nfshome/%s/appalachian_sector_barplot_emp_dominance.csv', user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save for export\n",
    "ggsave(sprintf('/nfshome/%s/appalachian_sector_barplot_emp_dominance.pdf', user))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting clusters must be treated as any other grouping variable, as each cluster must satisfy a minimum number of individuals and (when applicable) employers to pass disclosure control."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reminders\n",
    "Every single item designated for export, regardless of whether it is a .csv, .pdf, .png, or something else, must have corresponding proof in an input folder to show that every group used to create this statistic followed the present disclosure review guidelines.\n",
    "\n",
    "Additionally, when exporting employer-level characteristics, there must also be a lack of employer dominance as well as a count of at least three employers (or 10, depending on the state) per group."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "adrf_r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
